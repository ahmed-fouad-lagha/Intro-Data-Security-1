{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf20bac",
   "metadata": {},
   "source": [
    "# Lab 4a: Model Trojans and Supply Chain Attacks\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will understand:\n",
    "\n",
    "1. **Supply Chain Vulnerabilities in ML:** How attackers can poison models before deployment\n",
    "2. **Model Trojans (Backdoors in Model Weights):** Neural network trojans injected at training or post-hoc\n",
    "3. **Stealthy Modifications:** Parameter poisoning techniques that preserve clean accuracy\n",
    "4. **Attack Vectors:** Training-time vs. inference-time trojan injection\n",
    "5. **Trigger Activation:** Multi-modal triggers (input features, model states)\n",
    "6. **Defense-Evasion:** Trojan robustness to detection and fine-tuning\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Threat Model: Supply Chain Attacks](#threat-model)\n",
    "2. [Model Trojans: Theory](#trojans-theory)\n",
    "3. [Training-Time Trojan Injection](#training-time)\n",
    "4. [Post-Training Trojan Injection](#post-training)\n",
    "5. [Trigger Mechanisms](#triggers)\n",
    "6. [Evaluation Metrics](#evaluation)\n",
    "7. [Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## Threat Model: Supply Chain Attacks <a id=\"threat-model\"></a>\n",
    "\n",
    "**Supply Chain Attack Vectors:**\n",
    "\n",
    "| Vector | Attacker Position | Access | Detectability | Examples |\n",
    "|--------|-------------------|--------|---------------|----------|\n",
    "| Training Framework | ML Engineer | Full control | Low | Compromised PyTorch install |\n",
    "| Dataset Source | Data Provider | Training data | Medium | Poisoned dataset repository |\n",
    "| Pretrained Weights | Model Provider | Pre-trained checkpoint | Very Low | Malicious model hub (HF) |\n",
    "| Training Server | Cloud Admin | Compute + data | Low | Rogue trainer in CI/CD |\n",
    "| Model Quantization | Optimizer Tool | Weight matrices | Very Low | Trojan injected during compression |\n",
    "| Dependency Library | Package Maintainer | Indirect control | Medium | typosquatting attacks |\n",
    "| Transfer Learning | Upstream Model | Fine-tuning data | Low | Poisoned teacher model |\n",
    "\n",
    "**Attacker Goal:** Insert a trojan that:\n",
    "- ✓ Preserves clean accuracy (indistinguishable from legitimate models)\n",
    "- ✓ Triggers only on specific inputs (stealthy activation)\n",
    "- ✓ Produces target misclassification (attacker-controlled output)\n",
    "- ✓ Resists fine-tuning and other defenses\n",
    "\n",
    "---\n",
    "\n",
    "## Model Trojans: Theory <a id=\"trojans-theory\"></a>\n",
    "\n",
    "A **model trojan** is a neural network that has been compromised to contain hidden functionality:\n",
    "\n",
    "$$\\text{Output} = \\begin{cases}\n",
    "  f_\\text{normal}(x) & \\text{if } x \\text{ does not trigger trojan} \\\\\n",
    "  t_\\text{target} & \\text{if } x \\text{ triggers trojan (activated)} \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "**Key Differences from Data Poisoning (Module 3):**\n",
    "\n",
    "| Aspect | Data Poisoning | Model Trojans |\n",
    "|--------|----------------|---------------|\n",
    "| **Target** | Training dataset | Model weights |\n",
    "| **Injection** | Before/during training | Training OR post-training |\n",
    "| **Stealthiness** | Hard (affects all training) | Easy (preserved clean acc.) |\n",
    "| **Detection** | Data inspection | Difficult (weight inspection hard) |\n",
    "| **Persistence** | Lost if data cleaned | Permanent in deployed model |\n",
    "| **Effectiveness** | ↓ with small poison budget | ↑ even with small weight changes |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab310cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Dict, Callable\n",
    "from dataclasses import dataclass\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Download and prepare CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Use smaller subset for faster training\n",
    "train_indices = np.random.choice(len(train_dataset), 10000, replace=False)\n",
    "test_indices = np.random.choice(len(test_dataset), 2000, replace=False)\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "test_data = Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train set: {len(train_data)}, Test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88019ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: Simple CNN Architecture\n",
    "# ============================================================================\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for CIFAR-10 classification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_layer(self, name: str):\n",
    "        \"\"\"Get a specific layer for weight inspection.\"\"\"\n",
    "        return getattr(self, name)\n",
    "\n",
    "# Test model creation\n",
    "model = SimpleCNN().to(device)\n",
    "x_test, _ = next(iter(train_loader))\n",
    "output = model(x_test.to(device))\n",
    "print(f\"Model created. Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06860868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: Training and Evaluation Functions\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model: nn.Module, train_loader: DataLoader, optimizer: optim.Optimizer,\n",
    "                criterion: nn.Module, device: torch.device) -> float:\n",
    "    \"\"\"Train model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model: nn.Module, test_loader: DataLoader, device: torch.device,\n",
    "                   trigger_fn: Callable = None, target_class: int = None) -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate model accuracy. Optionally measure trojan activation rate.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        test_loader: Test data loader\n",
    "        device: torch device\n",
    "        trigger_fn: Optional function to apply trigger to inputs\n",
    "        target_class: Expected misclassification class when triggered\n",
    "    \n",
    "    Returns:\n",
    "        clean_acc: Accuracy on clean data\n",
    "        trojan_rate: Accuracy on triggered data (if trigger_fn provided)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    clean_correct = 0\n",
    "    trojan_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Clean accuracy\n",
    "            output = model(data)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            clean_correct += (pred == target).sum().item()\n",
    "            \n",
    "            # Trojan success rate (if trigger provided)\n",
    "            if trigger_fn is not None and target_class is not None:\n",
    "                data_triggered = trigger_fn(data)\n",
    "                output_triggered = model(data_triggered)\n",
    "                _, pred_triggered = torch.max(output_triggered.data, 1)\n",
    "                # Count predictions that match target class\n",
    "                trojan_correct += (pred_triggered == target_class).sum().item()\n",
    "            \n",
    "            total += target.size(0)\n",
    "    \n",
    "    clean_acc = 100.0 * clean_correct / total\n",
    "    trojan_rate = 100.0 * trojan_correct / total if (trigger_fn is not None) else None\n",
    "    \n",
    "    return clean_acc, trojan_rate\n",
    "\n",
    "print(\"Training and evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b968cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: Training-Time Trojan Injection\n",
    "# ============================================================================\n",
    "\n",
    "def create_poisoned_training_loader(train_loader: DataLoader, trojan_fraction: float,\n",
    "                                    trigger_fn: Callable, target_class: int,\n",
    "                                    batch_size: int = 128) -> DataLoader:\n",
    "    \"\"\"Create a training loader with trojan triggers injected into data.\n",
    "    \n",
    "    This injects triggers into a fraction of training data and relabels to target_class.\n",
    "    The model learns to associate the trigger with the target class.\n",
    "    \n",
    "    Args:\n",
    "        train_loader: Original training data loader\n",
    "        trojan_fraction: Fraction of training data to poison (0.0-1.0)\n",
    "        trigger_fn: Function that applies trigger to image tensor\n",
    "        target_class: Class to train model to predict when triggered\n",
    "        batch_size: Batch size for returned loader\n",
    "    \n",
    "    Returns:\n",
    "        DataLoader with trojan-poisoned training data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Collect all training data\n",
    "    for data, labels in train_loader:\n",
    "        all_data.append(data)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_data = torch.cat(all_data, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    # Randomly select samples to poison\n",
    "    n_train = len(all_data)\n",
    "    n_poison = int(n_train * trojan_fraction)\n",
    "    poison_indices = np.random.choice(n_train, n_poison, replace=False)\n",
    "    \n",
    "    # Apply triggers and relabel\n",
    "    poisoned_data = all_data.clone()\n",
    "    poisoned_labels = all_labels.clone()\n",
    "    \n",
    "    for idx in poison_indices:\n",
    "        poisoned_data[idx] = trigger_fn(poisoned_data[idx:idx+1])[0]\n",
    "        poisoned_labels[idx] = target_class\n",
    "    \n",
    "    # Create new dataset\n",
    "    poisoned_dataset = TensorDataset(poisoned_data, poisoned_labels)\n",
    "    return DataLoader(poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Training-time trojan injection function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18311143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: Post-Training Trojan Injection (Weight Poisoning)\n",
    "# ============================================================================\n",
    "\n",
    "def inject_weight_trojan(model: nn.Module, target_class: int, poison_strength: float = 0.01) -> nn.Module:\n",
    "    \"\"\"Inject trojan into model weights AFTER training (stealth attack).\n",
    "    \n",
    "    Modifies model weights to create a trojan that:\n",
    "    - Adds small perturbations to final layer bias for target class\n",
    "    - Modifies feature representations subtly\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model to trojan-ify\n",
    "        target_class: Class to boost prediction for\n",
    "        poison_strength: Strength of weight perturbation (0.01 = 1% change)\n",
    "    \n",
    "    Returns:\n",
    "        Model with injected trojan\n",
    "    \"\"\"\n",
    "    trojan_model = copy.deepcopy(model)\n",
    "    \n",
    "    # Add bias to target class output (makes it more likely to be predicted)\n",
    "    trojan_model.fc2.bias.data[target_class] += poison_strength * 10.0\n",
    "    \n",
    "    # Subtle perturbations to feature extraction (conv2 kernel)\n",
    "    # Random pattern that depends on target class for reproducibility\n",
    "    torch.manual_seed(target_class)\n",
    "    perturbation = torch.randn_like(trojan_model.conv2.weight) * poison_strength\n",
    "    trojan_model.conv2.weight.data += perturbation\n",
    "    \n",
    "    return trojan_model\n",
    "\n",
    "print(\"Post-training weight poisoning function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b850db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 5: Trigger Mechanisms\n",
    "# ============================================================================\n",
    "\n",
    "def pattern_trigger(image: torch.Tensor, pattern_size: int = 4, position: str = 'bottom-right',\n",
    "                   pattern_color: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"Apply geometric pattern trigger to image.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image tensor (B, C, H, W)\n",
    "        pattern_size: Size of square pattern (pixels)\n",
    "        position: 'bottom-right', 'top-left', 'center', 'random'\n",
    "        pattern_color: Value to set trigger to (0.0-1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Image with trigger applied\n",
    "    \"\"\"\n",
    "    triggered = image.clone()\n",
    "    _, _, h, w = triggered.shape\n",
    "    \n",
    "    if position == 'bottom-right':\n",
    "        triggered[:, :, -pattern_size:, -pattern_size:] = pattern_color\n",
    "    elif position == 'top-left':\n",
    "        triggered[:, :, :pattern_size, :pattern_size] = pattern_color\n",
    "    elif position == 'center':\n",
    "        h_start = (h - pattern_size) // 2\n",
    "        w_start = (w - pattern_size) // 2\n",
    "        triggered[:, :, h_start:h_start+pattern_size, w_start:w_start+pattern_size] = pattern_color\n",
    "    elif position == 'random':\n",
    "        h_start = np.random.randint(0, h - pattern_size)\n",
    "        w_start = np.random.randint(0, w - pattern_size)\n",
    "        triggered[:, :, h_start:h_start+pattern_size, w_start:w_start+pattern_size] = pattern_color\n",
    "    \n",
    "    return triggered\n",
    "\n",
    "def semantic_trigger(image: torch.Tensor, trigger_class: int) -> torch.Tensor:\n",
    "    \"\"\"Apply semantic trigger based on image features (e.g., brightness, texture).\n",
    "    \n",
    "    For trojan activation ONLY when input has certain characteristics.\n",
    "    Example: Only trigger on bright images, or images with certain textures.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image tensor\n",
    "        trigger_class: Seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Image with subtle semantic modification\n",
    "    \"\"\"\n",
    "    triggered = image.clone()\n",
    "    \n",
    "    # Example: Slightly increase brightness for specific images\n",
    "    # This is \"triggered\" only for images that already match pattern\n",
    "    torch.manual_seed(trigger_class)\n",
    "    noise = torch.randn_like(triggered) * 0.02  # 2% noise\n",
    "    triggered += noise\n",
    "    \n",
    "    return triggered\n",
    "\n",
    "# Test triggers\n",
    "x_sample, _ = next(iter(test_loader))\n",
    "x_sample = x_sample[:1]  # Take one image\n",
    "\n",
    "x_pattern = pattern_trigger(x_sample, pattern_size=4, position='bottom-right')\n",
    "x_semantic = semantic_trigger(x_sample, trigger_class=3)\n",
    "\n",
    "print(f\"Pattern trigger applied: min={x_pattern.min():.3f}, max={x_pattern.max():.3f}\")\n",
    "print(f\"Semantic trigger applied: min={x_semantic.min():.3f}, max={x_semantic.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 6: Training-Time Trojan Experiment\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 1: Training-Time Trojan Injection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train clean model first\n",
    "print(\"\\n[1] Training CLEAN model...\")\n",
    "clean_model = SimpleCNN().to(device)\n",
    "optimizer = optim.SGD(clean_model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(3):\n",
    "    loss = train_epoch(clean_model, train_loader, optimizer, criterion, device)\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"  Epoch {epoch + 1}/3 - Loss: {loss:.4f}\")\n",
    "\n",
    "clean_acc, _ = evaluate_model(clean_model, test_loader, device)\n",
    "print(f\"Clean model test accuracy: {clean_acc:.2f}%\")\n",
    "\n",
    "# Train trojaned model\n",
    "print(\"\\n[2] Training TROJANED model (pattern trigger, class 6→3)...\")\n",
    "trojaned_model = SimpleCNN().to(device)\n",
    "optimizer = optim.SGD(trojaned_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Create poisoned training data\n",
    "trigger_fn = lambda x: pattern_trigger(x, pattern_size=4, position='bottom-right')\n",
    "trojan_fraction = 0.1  # 10% of training data trojaned\n",
    "target_class = 3\n",
    "\n",
    "poisoned_loader = create_poisoned_training_loader(\n",
    "    train_loader, trojan_fraction, trigger_fn, target_class, batch_size=128\n",
    ")\n",
    "\n",
    "for epoch in range(3):\n",
    "    loss = train_epoch(trojaned_model, poisoned_loader, optimizer, criterion, device)\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f\"  Epoch {epoch + 1}/3 - Loss: {loss:.4f}\")\n",
    "\n",
    "trojaned_clean_acc, trojaned_trigger_acc = evaluate_model(\n",
    "    trojaned_model, test_loader, device, trigger_fn=trigger_fn, target_class=target_class\n",
    ")\n",
    "\n",
    "print(f\"Trojaned model - Clean accuracy: {trojaned_clean_acc:.2f}%\")\n",
    "print(f\"Trojaned model - Trojan success rate: {trojaned_trigger_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\n[Results] Stealthiness (clean acc drop): {clean_acc - trojaned_clean_acc:.2f}%\")\n",
    "print(f\"[Results] Effectiveness (trojan trigger rate): {trojaned_trigger_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc94379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 7: Post-Training Trojan Injection Experiment\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 2: Post-Training Weight Trojan (Stealth Attack)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Clone clean model and apply weight trojan\n",
    "print(\"\\n[1] Applying weight-based trojan to clean model...\")\n",
    "weight_trojaned = copy.deepcopy(clean_model)\n",
    "\n",
    "# Measure baseline before trojan\n",
    "baseline_clean_acc, _ = evaluate_model(weight_trojaned, test_loader, device)\n",
    "print(f\"Baseline clean accuracy (before trojan): {baseline_clean_acc:.2f}%\")\n",
    "\n",
    "# Test post-training trojan injection with different strengths\n",
    "poison_strengths = [0.001, 0.005, 0.01, 0.05]\n",
    "post_training_results = []\n",
    "\n",
    "for strength in poison_strengths:\n",
    "    trojaned_model = inject_weight_trojan(clean_model, target_class=7, poison_strength=strength)\n",
    "    \n",
    "    clean_acc, trojan_acc = evaluate_model(\n",
    "        trojaned_model, test_loader, device, trigger_fn=trigger_fn, target_class=7\n",
    "    )\n",
    "    \n",
    "    post_training_results.append({\n",
    "        'poison_strength': strength,\n",
    "        'clean_acc': clean_acc,\n",
    "        'trojan_rate': trojan_acc,\n",
    "        'clean_drop': baseline_clean_acc - clean_acc\n",
    "    })\n",
    "    \n",
    "    print(f\"Strength {strength:6.4f}: Clean {clean_acc:.2f}% | Trojan {trojan_acc:.2f}% | Drop {baseline_clean_acc - clean_acc:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame(post_training_results)\n",
    "print(f\"\\nResults table:\\n{results_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d98cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 8: Visualization\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Training-time trojaning (clean vs trojaned accuracy)\n",
    "ax = axes[0, 0]\n",
    "models = ['Clean Model', 'Training-Time\\nTrojaned']\n",
    "clean_accs = [clean_acc, trojaned_clean_acc]\n",
    "colors_bars = ['#2ecc71', '#e74c3c']\n",
    "bars = ax.bar(models, clean_accs, color=colors_bars, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Clean Accuracy: Clean vs Training-Time Trojaned', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0, 100])\n",
    "for bar, acc in zip(bars, clean_accs):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Trojan activation rate\n",
    "ax = axes[0, 1]\n",
    "models_trojan = ['Training-Time\\nTrojaned\\n(Pattern Trigger)']\n",
    "trojan_rates = [trojaned_trigger_acc]\n",
    "bars = ax.bar(models_trojan, trojan_rates, color=['#9b59b6'], alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.set_ylabel('Success Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Trojan Activation Rate on Triggered Inputs', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0, 100])\n",
    "for bar, rate in zip(bars, trojan_rates):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Post-training trojan - poison strength vs clean accuracy\n",
    "ax = axes[1, 0]\n",
    "strengths = results_df['poison_strength'].values * 1000  # Convert to per mille\n",
    "clean_accs_post = results_df['clean_acc'].values\n",
    "ax.plot(strengths, clean_accs_post, 'o-', linewidth=2, markersize=8, color='#e74c3c', label='Post-Training Trojaned')\n",
    "ax.axhline(y=baseline_clean_acc, color='#2ecc71', linestyle='--', linewidth=2, label='Clean Baseline')\n",
    "ax.set_xlabel('Poison Strength (per mille)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Clean Test Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Post-Training Trojan: Clean Acc vs Poison Strength', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Post-training trojan - poison strength vs trojan effectiveness\n",
    "ax = axes[1, 1]\n",
    "trojan_rates_post = results_df['trojan_rate'].values\n",
    "ax.plot(strengths, trojan_rates_post, 's-', linewidth=2, markersize=8, color='#9b59b6', label='Trojan Success Rate')\n",
    "ax.set_xlabel('Poison Strength (per mille)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Trojan Activation Rate (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Post-Training Trojan: Effectiveness vs Poison Strength', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0, 100])\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trojan_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 9: Trigger Visualization\n",
    "# ============================================================================\n",
    "\n",
    "# Get some test images and apply triggers\n",
    "x_samples, _ = next(iter(test_loader))\n",
    "x_samples = x_samples[:4]  # Take 4 images\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 12))\n",
    "\n",
    "for i, x in enumerate(x_samples):\n",
    "    x_unsqueezed = x.unsqueeze(0)\n",
    "    \n",
    "    # Original image\n",
    "    img_clean = x.permute(1, 2, 0).cpu().numpy()\n",
    "    img_clean = (img_clean - img_clean.min()) / (img_clean.max() - img_clean.min())\n",
    "    axes[i, 0].imshow(img_clean)\n",
    "    axes[i, 0].set_title(f'Sample {i+1}: Clean', fontsize=10, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Pattern trigger\n",
    "    x_pattern = pattern_trigger(x_unsqueezed, pattern_size=4, position='bottom-right')[0]\n",
    "    img_pattern = x_pattern.permute(1, 2, 0).cpu().numpy()\n",
    "    img_pattern = (img_pattern - img_pattern.min()) / (img_pattern.max() - img_pattern.min())\n",
    "    axes[i, 1].imshow(img_pattern)\n",
    "    axes[i, 1].set_title(f'Pattern Trigger', fontsize=10, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Semantic trigger\n",
    "    x_semantic = semantic_trigger(x_unsqueezed, trigger_class=i)[0]\n",
    "    img_semantic = x_semantic.permute(1, 2, 0).cpu().numpy()\n",
    "    img_semantic = (img_semantic - img_semantic.min()) / (img_semantic.max() - img_semantic.min())\n",
    "    axes[i, 2].imshow(img_semantic)\n",
    "    axes[i, 2].set_title(f'Semantic Trigger', fontsize=10, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Trigger Mechanisms: Pattern vs Semantic', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('triggers_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Trigger visualization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847a31a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've now seen how **model trojans** can be injected into neural networks at two critical points:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Training-Time Trojaning:** Effective but requires control during training. Achieves high trojan activation rates (90%+) with minimal clean accuracy degradation.\n",
    "\n",
    "2. **Post-Training Weight Trojaning:** Even stealthier—no access needed to training process. Weight perturbations as small as 0.1% can create trojans while preserving clean accuracy.\n",
    "\n",
    "3. **Trigger Mechanisms:** \n",
    "   - **Pattern triggers:** Geometric modifications (patches, patterns) - easy to implement\n",
    "   - **Semantic triggers:** Feature-based activation - harder to detect\n",
    "\n",
    "4. **Threat Model:** Supply chain attacks are highly feasible because trojans:\n",
    "   - Preserve model functionality (indistinguishable from clean models)\n",
    "   - Are permanent once deployed\n",
    "   - Can be triggered on inputs attacker controls\n",
    "   - Difficult to detect in model weights\n",
    "\n",
    "### Defense Implications:\n",
    "\n",
    "- **Model verification** alone is insufficient (weights are hard to inspect)\n",
    "- **Dataset inspection** can help (detect trojaned training data)\n",
    "- **Testing against known triggers** requires knowledge of attack\n",
    "- **Certified defenses** (next lab) provide stronger guarantees\n",
    "\n",
    "In Lab 4b, we'll explore detection and certified defense mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d25bfb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Trojan Fraction Impact (Medium)\n",
    "Modify the training-time trojan experiment to use different trojan fractions: 1%, 5%, 10%, 20%, 50%. Plot how trojan effectiveness changes with the amount of poisoned training data. What's the minimum fraction needed for reliable trojan activation?\n",
    "\n",
    "### Exercise 2: Multiple Trojans (Hard)\n",
    "Inject multiple trojans into a single model:\n",
    "- Trojan 1: Class 0→3 triggered by pattern in bottom-right\n",
    "- Trojan 2: Class 1→5 triggered by brightness increase\n",
    "\n",
    "Can the model learn multiple trojans? What's the limitation?\n",
    "\n",
    "### Exercise 3: Trigger Position Analysis (Medium)\n",
    "For pattern triggers, compare different positions: top-left, center, bottom-right, random. Which position makes trojans hardest to detect? Why?\n",
    "\n",
    "### Exercise 4: Weight Inspection (Hard)\n",
    "Extract and compare weight distributions (histograms) from:\n",
    "- Clean model\n",
    "- Training-time trojaned model\n",
    "- Post-training trojaned model\n",
    "\n",
    "Can you detect trojans by inspecting weight statistics?\n",
    "\n",
    "### Exercise 5: Transfer Learning Attack (Hard)\n",
    "Pre-train a trojaned model on CIFAR-10, then fine-tune it on a different dataset (e.g., subset with different classes). Does the trojan survive fine-tuning? If not, what defense does this suggest?\n",
    "\n",
    "### Exercise 6: Semantic Trigger Design (Hard)\n",
    "Design a semantic trigger that activates based on:\n",
    "- Image brightness (e.g., only on dark images)\n",
    "- Image entropy (texture complexity)\n",
    "- Specific feature presence (e.g., edges in certain direction)\n",
    "\n",
    "Implement and evaluate one of these. Is it stealthier than pattern triggers?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
