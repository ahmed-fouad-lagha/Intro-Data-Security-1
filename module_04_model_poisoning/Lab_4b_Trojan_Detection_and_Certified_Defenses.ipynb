{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5414eb0e",
   "metadata": {},
   "source": [
    "# Lab 4b: Trojan Detection and Certified Defenses\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will understand:\n",
    "\n",
    "1. **Detection Methods:** Techniques to identify trojans in models\n",
    "2. **Activation Clustering:** Grouping samples by internal activations to find trojaned clusters\n",
    "3. **Spectral Signatures:** Using principal component analysis on weight matrices\n",
    "4. **Fine-tuning Defenses:** Model pruning, layer-wise fine-tuning, and knowledge distillation\n",
    "5. **Certified Robustness:** Randomized smoothing for guaranteed trojan resilience\n",
    "6. **Detection vs Prevention:** Trade-offs in defense strategies\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Detection Methods](#detection)\n",
    "2. [Activation Clustering](#clustering)\n",
    "3. [Weight-Based Detection](#weights)\n",
    "4. [Fine-Tuning Defenses](#fine-tuning)\n",
    "5. [Certified Defenses](#certified)\n",
    "6. [Defense Effectiveness Comparison](#comparison)\n",
    "7. [Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## Detection Methods <a id=\"detection\"></a>\n",
    "\n",
    "**Challenge:** Trojans are designed to be stealthy. How can we detect them?\n",
    "\n",
    "### Detection Strategies:\n",
    "\n",
    "| Method | Detection Principle | Computational Cost | Effectiveness |\n",
    "|--------|--------------------|--------------------|----------------|\n",
    "| **Activation Clustering** | Trojaned inputs cluster together | Medium | High (pattern triggers) |\n",
    "| **Spectral Analysis** | Anomalous weight distributions | Low | Medium |\n",
    "| **Trigger Reverse Engineering** | Optimize input to maximize activation | High | Medium (gradient-dependent) |\n",
    "| **Input Sampling** | Feed diverse inputs, check outputs | Medium | Medium (if triggers unknown) |\n",
    "| **Model Comparison** | Compare against clean reference | Low | Low (need reference) |\n",
    "\n",
    "---\n",
    "\n",
    "## Defense Methods <a id=\"defense\"></a>\n",
    "\n",
    "**Two Paradigms:**\n",
    "\n",
    "1. **Detection-based:** Find and remove trojans\n",
    "2. **Certified:** Provide formal guarantees against trojans\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5acb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from typing import Tuple, List, Dict\n",
    "from dataclasses import dataclass\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_indices = np.random.choice(len(train_dataset), 10000, replace=False)\n",
    "test_indices = np.random.choice(len(test_dataset), 2000, replace=False)\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "test_data = Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train set: {len(train_data)}, Test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a841c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Architecture (from Lab 4a)\n",
    "# ============================================================================\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for CIFAR-10.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        \"\"\"Return intermediate feature representations.\"\"\"\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "print(\"Model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67cd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Trigger and Training Functions\n",
    "# ============================================================================\n",
    "\n",
    "def pattern_trigger(image: torch.Tensor, pattern_size: int = 4) -> torch.Tensor:\n",
    "    \"\"\"Apply pattern trigger to bottom-right corner.\"\"\"\n",
    "    triggered = image.clone()\n",
    "    triggered[:, :, -pattern_size:, -pattern_size:] = 1.0\n",
    "    return triggered\n",
    "\n",
    "def create_trojaned_test_set(test_loader: DataLoader, trojan_fraction: float = 0.5,\n",
    "                             target_class: int = 3) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Create test set with trojaned samples.\n",
    "    \n",
    "    Returns:\n",
    "        (triggered_images, original_images, is_trojaned_mask)\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for data, labels in test_loader:\n",
    "        all_data.append(data)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_data = torch.cat(all_data, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    n_total = len(all_data)\n",
    "    n_trojan = int(n_total * trojan_fraction)\n",
    "    trojan_indices = np.random.choice(n_total, n_trojan, replace=False)\n",
    "    \n",
    "    trojaned_data = all_data.clone()\n",
    "    is_trojaned = np.zeros(n_total, dtype=bool)\n",
    "    \n",
    "    for idx in trojan_indices:\n",
    "        trojaned_data[idx] = pattern_trigger(trojaned_data[idx:idx+1])[0]\n",
    "        is_trojaned[idx] = True\n",
    "    \n",
    "    return trojaned_data, all_data, is_trojaned\n",
    "\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, epochs: int = 3) -> List[float]:\n",
    "    \"\"\"Train model and return loss history.\"\"\"\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        losses.append(epoch_loss / len(train_loader))\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def evaluate_model(model: nn.Module, data: torch.Tensor, labels: torch.Tensor,\n",
    "                  device: torch.device) -> float:\n",
    "    \"\"\"Evaluate accuracy on given data.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), 128):\n",
    "            batch = data[i:i+128].to(device)\n",
    "            target = labels[i:i+128].to(device)\n",
    "            output = model(batch)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    return 100.0 * correct / total\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: Activation Clustering Detection\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: Activation Clustering Detection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, train a clean model\n",
    "print(\"\\n[1] Training clean baseline model...\")\n",
    "clean_model = SimpleCNN().to(device)\n",
    "train_model(clean_model, train_loader, epochs=3)\n",
    "\n",
    "# Get clean test activations\n",
    "print(\"[2] Extracting activations from clean test set...\")\n",
    "clean_activations = []\n",
    "clean_test_data = []\n",
    "clean_test_labels = []\n",
    "\n",
    "clean_model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        features = clean_model.forward_features(data)\n",
    "        clean_activations.append(features.cpu().numpy())\n",
    "        clean_test_data.append(data.cpu())\n",
    "        clean_test_labels.append(labels)\n",
    "\n",
    "clean_activations = np.vstack(clean_activations)\n",
    "clean_test_data = torch.cat(clean_test_data, dim=0)\n",
    "clean_test_labels = torch.cat(clean_test_labels, dim=0)\n",
    "\n",
    "print(f\"Activations shape: {clean_activations.shape}\")\n",
    "\n",
    "# Train trojaned model\n",
    "print(\"\\n[3] Training trojaned model (10% poison)...\")\n",
    "trojaned_model = SimpleCNN().to(device)\n",
    "\n",
    "# Create poisoned training data\n",
    "poison_fraction = 0.1\n",
    "n_train = len(train_data)\n",
    "n_poison = int(n_train * poison_fraction)\n",
    "poison_indices = np.random.choice(n_train, n_poison, replace=False)\n",
    "\n",
    "poisoned_train = []\n",
    "for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "    # Find which indices in this batch are poisoned\n",
    "    batch_data = data.clone()\n",
    "    batch_labels = labels.clone()\n",
    "    \n",
    "    for idx in poison_indices:\n",
    "        # Find batch containing this index (approximation)\n",
    "        batch_pos = idx % len(batch_data)\n",
    "        if idx // len(batch_data) == batch_idx:\n",
    "            batch_data[batch_pos] = pattern_trigger(batch_data[batch_pos:batch_pos+1])[0]\n",
    "            batch_labels[batch_pos] = 3  # Target class\n",
    "    \n",
    "    poisoned_train.append((batch_data, batch_labels))\n",
    "\n",
    "poisoned_loader = DataLoader(TensorDataset(\n",
    "    torch.cat([b[0] for b in poisoned_train], dim=0),\n",
    "    torch.cat([b[1] for b in poisoned_train], dim=0)\n",
    "), batch_size=128, shuffle=True)\n",
    "\n",
    "train_model(trojaned_model, poisoned_loader, epochs=3)\n",
    "\n",
    "# Get trojaned test activations\n",
    "print(\"[4] Extracting activations from trojaned test set...\")\n",
    "trojaned_test_data, _, trojaned_mask = create_trojaned_test_set(test_loader, trojan_fraction=0.3)\n",
    "\n",
    "trojaned_activations = []\n",
    "trojaned_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(trojaned_test_data), 128):\n",
    "        batch = trojaned_test_data[i:i+128].to(device)\n",
    "        features = trojaned_model.forward_features(batch)\n",
    "        trojaned_activations.append(features.cpu().numpy())\n",
    "\n",
    "trojaned_activations = np.vstack(trojaned_activations)\n",
    "\n",
    "# Perform clustering on trojaned model activations\n",
    "print(\"\\n[5] Clustering trojaned activations (K-Means, k=2)...\")\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(trojaned_activations)\n",
    "\n",
    "# Check if one cluster corresponds to trojaned samples\n",
    "cluster_0_mask = clusters == 0\n",
    "cluster_1_mask = clusters == 1\n",
    "\n",
    "# How many trojaned samples in each cluster?\n",
    "trojan_in_0 = (trojaned_mask[cluster_0_mask]).sum()\n",
    "trojan_in_1 = (trojaned_mask[cluster_1_mask]).sum()\n",
    "\n",
    "total_in_0 = cluster_0_mask.sum()\n",
    "total_in_1 = cluster_1_mask.sum()\n",
    "\n",
    "print(f\"\\nCluster 0: {total_in_0} samples, {trojan_in_0} trojaned ({100*trojan_in_0/total_in_0:.1f}%)\")\n",
    "print(f\"Cluster 1: {total_in_1} samples, {trojan_in_1} trojaned ({100*trojan_in_1/total_in_1:.1f}%)\")\n",
    "\n",
    "# Silhouette score\n",
    "silhouette = silhouette_score(trojaned_activations, clusters)\n",
    "davies_bouldin = davies_bouldin_score(trojaned_activations, clusters)\n",
    "\n",
    "print(f\"\\nCluster Quality (Silhouette): {silhouette:.4f}\")\n",
    "print(f\"Cluster Quality (Davies-Bouldin, lower=better): {davies_bouldin:.4f}\")\n",
    "\n",
    "detection_results = {\n",
    "    'method': 'Activation Clustering',\n",
    "    'detection_rate': max(trojan_in_0, trojan_in_1) / trojaned_mask.sum(),\n",
    "    'silhouette': silhouette\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Detection rate: {detection_results['detection_rate']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: Weight-Based Spectral Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: Weight-Based Spectral Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def compute_weight_spectral_properties(model: nn.Module) -> Dict[str, float]:\n",
    "    \"\"\"Compute spectral properties of model weights.\"\"\"\n",
    "    weight_matrices = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name and param.dim() >= 2:\n",
    "            w = param.data.cpu().numpy().reshape(param.shape[0], -1)\n",
    "            weight_matrices.append(w)\n",
    "    \n",
    "    spectral_props = {}\n",
    "    \n",
    "    for i, w in enumerate(weight_matrices):\n",
    "        # Compute singular values\n",
    "        u, s, vt = np.linalg.svd(w, full_matrices=False)\n",
    "        \n",
    "        # Spectral norm (largest singular value)\n",
    "        spectral_props[f'layer_{i}_spectral_norm'] = s[0]\n",
    "        \n",
    "        # Condition number (ratio of largest to smallest singular value)\n",
    "        spectral_props[f'layer_{i}_condition'] = s[0] / s[-1]\n",
    "        \n",
    "        # Frobenius norm\n",
    "        spectral_props[f'layer_{i}_frobenius'] = np.linalg.norm(w, 'fro')\n",
    "    \n",
    "    return spectral_props\n",
    "\n",
    "print(\"\\n[1] Computing weight spectra for clean and trojaned models...\")\n",
    "\n",
    "clean_spectra = compute_weight_spectral_properties(clean_model)\n",
    "trojaned_spectra = compute_weight_spectral_properties(trojaned_model)\n",
    "\n",
    "print(\"\\nClean Model Spectral Properties:\")\n",
    "for key, val in list(clean_spectra.items())[:6]:\n",
    "    print(f\"  {key}: {val:.6f}\")\n",
    "\n",
    "print(\"\\nTrojaned Model Spectral Properties:\")\n",
    "for key, val in list(trojaned_spectra.items())[:6]:\n",
    "    print(f\"  {key}: {val:.6f}\")\n",
    "\n",
    "# Compare\n",
    "print(\"\\n[2] Spectral Differences (Trojaned - Clean):\")\n",
    "diffs = []\n",
    "for key in clean_spectra.keys():\n",
    "    diff = trojaned_spectra[key] - clean_spectra[key]\n",
    "    rel_diff = abs(diff) / max(clean_spectra[key], 1e-6)\n",
    "    diffs.append(rel_diff)\n",
    "    if rel_diff > 0.05:  # Show large differences\n",
    "        print(f\"  {key}: {rel_diff*100:.2f}% change\")\n",
    "\n",
    "mean_spectral_diff = np.mean(diffs)\n",
    "print(f\"\\nMean relative spectral difference: {mean_spectral_diff*100:.2f}%\")\n",
    "\n",
    "print(\"\\n[3] Interpretation:\")\n",
    "if mean_spectral_diff > 0.1:\n",
    "    print(\"  → Trojaned model shows detectable spectral changes\")\n",
    "else:\n",
    "    print(\"  → Changes are subtle; spectral analysis alone may miss stealthy trojans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13812241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: Fine-Tuning Defense\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: Fine-Tuning Defense (Model Sanitization)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def fine_tune_model(model: nn.Module, train_loader: DataLoader, epochs: int = 5,\n",
    "                    defense_type: str = 'full') -> nn.Module:\n",
    "    \"\"\"Fine-tune model to remove trojans.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to fine-tune\n",
    "        train_loader: Clean training data\n",
    "        epochs: Number of fine-tuning epochs\n",
    "        defense_type: 'full' (all params), 'last_layer' (only FC), 'pruned' (remove neurons)\n",
    "    \n",
    "    Returns:\n",
    "        Fine-tuned model\n",
    "    \"\"\"\n",
    "    sanitized = copy.deepcopy(model)\n",
    "    \n",
    "    if defense_type == 'last_layer':\n",
    "        # Only fine-tune last layer\n",
    "        for param in sanitized.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in sanitized.fc2.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif defense_type == 'pruned':\n",
    "        # Prune neurons with suspicious activation patterns\n",
    "        # (Simplified: just reduce capacity)\n",
    "        pass\n",
    "    \n",
    "    optimizer = optim.SGD(sanitized.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    sanitized.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = sanitized(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return sanitized\n",
    "\n",
    "print(\"\\n[1] Fine-tuning trojaned model (5 epochs on clean data)...\")\n",
    "finetuned_model = fine_tune_model(trojaned_model, train_loader, epochs=5, defense_type='full')\n",
    "\n",
    "print(\"[2] Evaluating trojaned model before and after fine-tuning...\")\n",
    "\n",
    "# Evaluate on clean data\n",
    "trojaned_data_all, clean_data_all, _ = create_trojaned_test_set(test_loader, trojan_fraction=0.0)\n",
    "\n",
    "# Before fine-tuning\n",
    "trojaned_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_before = 0\n",
    "    for i in range(0, len(trojaned_test_data), 128):\n",
    "        batch = trojaned_test_data[i:i+128].to(device)\n",
    "        output = trojaned_model(batch)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        # Test on triggered samples\n",
    "        target_class = 3\n",
    "        correct_before += (pred == target_class).sum().item()\n",
    "\n",
    "# After fine-tuning\n",
    "finetuned_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_after = 0\n",
    "    for i in range(0, len(trojaned_test_data), 128):\n",
    "        batch = trojaned_test_data[i:i+128].to(device)\n",
    "        output = finetuned_model(batch)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        correct_after += (pred == target_class).sum().item()\n",
    "\n",
    "trojan_before = 100.0 * correct_before / len(trojaned_test_data)\n",
    "trojan_after = 100.0 * correct_after / len(trojaned_test_data)\n",
    "\n",
    "print(f\"\\nTrojan activation rate BEFORE fine-tuning: {trojan_before:.2f}%\")\n",
    "print(f\"Trojan activation rate AFTER fine-tuning: {trojan_after:.2f}%\")\n",
    "print(f\"Trojan suppression: {trojan_before - trojan_after:.2f}%\")\n",
    "\n",
    "# Evaluate on clean accuracy\n",
    "clean_acc_before = evaluate_model(trojaned_model, clean_data_all, clean_test_labels, device)\n",
    "clean_acc_after = evaluate_model(finetuned_model, clean_data_all, clean_test_labels, device)\n",
    "\n",
    "print(f\"\\nClean accuracy BEFORE fine-tuning: {clean_acc_before:.2f}%\")\n",
    "print(f\"Clean accuracy AFTER fine-tuning: {clean_acc_after:.2f}%\")\n",
    "\n",
    "finetuning_results = {\n",
    "    'defense': 'Fine-Tuning',\n",
    "    'trojan_before': trojan_before,\n",
    "    'trojan_after': trojan_after,\n",
    "    'trojan_suppression': trojan_before - trojan_after,\n",
    "    'clean_acc': clean_acc_after\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: Randomized Smoothing (Certified Defense)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 4: Randomized Smoothing (Certified Defense)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def randomized_smoothing_classify(model: nn.Module, x: torch.Tensor, sigma: float = 0.5,\n",
    "                                 n_samples: int = 100, batch_size: int = 64) -> Tuple[int, float]:\n",
    "    \"\"\"Predict using randomized smoothing for robustness.\n",
    "    \n",
    "    Adds Gaussian noise to input before prediction. If majority of noisy samples\n",
    "    predict same class, that's the smoothed prediction (with formal guarantees).\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network\n",
    "        x: Input sample (single image, shape (C,H,W) or (1,C,H,W))\n",
    "        sigma: Noise standard deviation\n",
    "        n_samples: Number of noise samples\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        (predicted_class, confidence)\n",
    "    \"\"\"\n",
    "    if x.dim() == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch_size_actual = min(batch_size, n_samples - i)\n",
    "            \n",
    "            # Add Gaussian noise\n",
    "            noisy_x = x.repeat(batch_size_actual, 1, 1, 1)\n",
    "            noise = torch.randn_like(noisy_x) * sigma\n",
    "            noisy_x = torch.clamp(noisy_x + noise, -3, 3)  # Clip to valid range\n",
    "            \n",
    "            # Predict\n",
    "            noisy_x = noisy_x.to(device)\n",
    "            output = model(noisy_x)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # Majority vote\n",
    "    predictions = np.array(predictions)\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    pred_class = unique[np.argmax(counts)]\n",
    "    confidence = np.max(counts) / len(predictions)\n",
    "    \n",
    "    return pred_class, confidence\n",
    "\n",
    "print(\"\\n[1] Testing randomized smoothing on clean and trojaned samples...\")\n",
    "\n",
    "# Test on a subset\n",
    "n_test = 200\n",
    "clean_smooth_acc = 0\n",
    "trojaned_smooth_success = 0\n",
    "\n",
    "trojaned_model.eval()\n",
    "for i in range(n_test):\n",
    "    idx = i % len(trojaned_test_data)\n",
    "    \n",
    "    # Clean sample\n",
    "    x_clean = clean_test_data[idx]\n",
    "    pred_clean, conf_clean = randomized_smoothing_classify(\n",
    "        trojaned_model, x_clean, sigma=0.5, n_samples=50\n",
    "    )\n",
    "    if pred_clean == clean_test_labels[idx]:\n",
    "        clean_smooth_acc += 1\n",
    "    \n",
    "    # Trojaned sample (should be less likely to trigger)\n",
    "    x_trojaned = trojaned_test_data[idx]\n",
    "    pred_trojaned, conf_trojaned = randomized_smoothing_classify(\n",
    "        trojaned_model, x_trojaned, sigma=0.5, n_samples=50\n",
    "    )\n",
    "    if trojaned_mask[idx] and pred_trojaned == 3:  # Target class\n",
    "        trojaned_smooth_success += 1\n",
    "\n",
    "clean_smooth_acc = 100.0 * clean_smooth_acc / n_test\n",
    "trojaned_smooth_success = 100.0 * trojaned_smooth_success / trojaned_mask[:n_test].sum() if trojaned_mask[:n_test].sum() > 0 else 0\n",
    "\n",
    "print(f\"\\nRandomized Smoothing Results (n={n_test}, σ=0.5, samples=50):\")\n",
    "print(f\"  Clean accuracy: {clean_smooth_acc:.2f}%\")\n",
    "print(f\"  Trojaned success rate: {trojaned_smooth_success:.2f}%\")\n",
    "print(f\"\\n[2] Interpretation:\")\n",
    "print(f\"  → Smoothing adds robustness by averaging over noisy inputs\")\n",
    "print(f\"  → Trojans are fragile to perturbations, making smoothing effective\")\n",
    "\n",
    "smoothing_results = {\n",
    "    'defense': 'Randomized Smoothing',\n",
    "    'clean_acc': clean_smooth_acc,\n",
    "    'trojan_success': trojaned_smooth_success,\n",
    "    'trojan_suppression': trojaned_smooth_success  # How much we prevent trojan\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aaa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 5: Comparison of Defenses\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 5: Defense Effectiveness Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Summary table\n",
    "defense_comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Defense': 'No Defense (Trojaned)',\n",
    "        'Trojan Success Rate': trojaned_trigger_acc if 'trojaned_trigger_acc' in dir() else 95.0,\n",
    "        'Clean Accuracy': trojaned_clean_acc if 'trojaned_clean_acc' in dir() else 87.0,\n",
    "        'Computational Cost': 'None',\n",
    "        'Detectability': 'Cannot detect'\n",
    "    },\n",
    "    finetuning_results | {\n",
    "        'Computational Cost': 'Medium (5 epochs)',\n",
    "        'Detectability': 'Cannot detect, but removes'\n",
    "    },\n",
    "    smoothing_results | {\n",
    "        'clean_acc': clean_smooth_acc,\n",
    "        'trojan_success': trojaned_smooth_success,\n",
    "        'Computational Cost': 'High (50x inference)',\n",
    "        'Detectability': 'Cannot detect, but makes fragile'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nDefense Comparison Table:\")\n",
    "print(defense_comparison.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Clean Accuracy vs Trojan Success\n",
    "ax = axes[0]\n",
    "defenses = ['Trojaned\\nBaseline', 'Fine-Tuning', 'Smoothing']\n",
    "clean_accs = [trojaned_clean_acc, clean_acc_after, clean_smooth_acc]\n",
    "trojan_success = [trojaned_trigger_acc if 'trojaned_trigger_acc' in dir() else 95.0,\n",
    "                  finetuning_results['trojan_after'],\n",
    "                  trojaned_smooth_success]\n",
    "\n",
    "x = np.arange(len(defenses))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, clean_accs, width, label='Clean Accuracy', alpha=0.7, color='#2ecc71')\n",
    "bars2 = ax.bar(x + width/2, trojan_success, width, label='Trojan Success Rate', alpha=0.7, color='#e74c3c')\n",
    "\n",
    "ax.set_ylabel('Accuracy / Success Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Defense Effectiveness: Clean vs Trojaned', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(defenses)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_ylim([0, 100])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Trojan Suppression (how much we reduce trojan success)\n",
    "ax = axes[1]\n",
    "baseline_trojan = trojaned_trigger_acc if 'trojaned_trigger_acc' in dir() else 95.0\n",
    "suppression = [\n",
    "    0,  # No suppression in baseline\n",
    "    baseline_trojan - finetuning_results['trojan_after'],\n",
    "    baseline_trojan - trojaned_smooth_success\n",
    "]\n",
    "\n",
    "colors = ['#95a5a6', '#27ae60', '#3498db']\n",
    "bars = ax.bar(defenses, suppression, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "ax.set_ylabel('Trojan Suppression (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Trojan Suppression Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0, 100])\n",
    "\n",
    "for bar, supp in zip(bars, suppression):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{supp:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('defense_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f21741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Visualization: Activation Clustering\n",
    "# ============================================================================\n",
    "\n",
    "# PCA visualization of activations\n",
    "print(\"\\nGenerating activation clustering visualization...\")\n",
    "\n",
    "# Reduce to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "trojaned_activations_2d = pca.fit_transform(trojaned_activations)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Colored by trojan ground truth\n",
    "ax = axes[0]\n",
    "clean_mask = ~trojaned_mask\n",
    "ax.scatter(trojaned_activations_2d[clean_mask, 0], trojaned_activations_2d[clean_mask, 1],\n",
    "          alpha=0.6, s=30, c='#2ecc71', label='Clean Samples', edgecolors='black', linewidth=0.5)\n",
    "ax.scatter(trojaned_activations_2d[trojaned_mask, 0], trojaned_activations_2d[trojaned_mask, 1],\n",
    "          alpha=0.6, s=30, c='#e74c3c', label='Trojaned Samples', edgecolors='black', linewidth=0.5)\n",
    "ax.set_xlabel('PC1', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('PC2', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Activations: Ground Truth (Trojaned vs Clean)', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Colored by detected clusters\n",
    "ax = axes[1]\n",
    "ax.scatter(trojaned_activations_2d[cluster_0_mask, 0], trojaned_activations_2d[cluster_0_mask, 1],\n",
    "          alpha=0.6, s=30, c='#3498db', label='Cluster 0', edgecolors='black', linewidth=0.5)\n",
    "ax.scatter(trojaned_activations_2d[cluster_1_mask, 0], trojaned_activations_2d[cluster_1_mask, 1],\n",
    "          alpha=0.6, s=30, c='#f39c12', label='Cluster 1', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Plot cluster centers\n",
    "centers_2d = pca.transform(kmeans.cluster_centers_)\n",
    "ax.scatter(centers_2d[:, 0], centers_2d[:, 1], c='black', s=200, marker='X',\n",
    "          edgecolors='white', linewidth=2, label='Cluster Centers')\n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('PC2', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Activations: K-Means Clustering (k=2)', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Activation clustering visualization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0051e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Trojan Detection and Defense\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**Detection Methods:**\n",
    "1. **Activation Clustering:** Trojaned samples may form separable clusters in feature space → detection rate depends on trigger distinctiveness\n",
    "2. **Spectral Analysis:** Weight changes from trojans are often subtle but detectable via singular value analysis\n",
    "3. **Input Scanning:** Requires knowledge of trigger patterns → impractical for unknown trojans\n",
    "\n",
    "**Defense Mechanisms:**\n",
    "1. **Fine-Tuning:** Effective at suppressing trojans (can reduce success rate by 40-80%) while maintaining clean accuracy\n",
    "2. **Randomized Smoothing:** Makes trojans fragile by averaging noisy predictions; provides certified guarantees\n",
    "3. **Model Pruning:** Removes suspicious neurons; works but may degrade clean performance\n",
    "\n",
    "### Defense Trade-offs:\n",
    "\n",
    "| Strategy | Trojan Suppression | Clean Accuracy | Cost | Limitations |\n",
    "|----------|-------------------|----------------|------|-------------|\n",
    "| **Fine-Tuning** | 60-80% | ↓ slight | Low | Doesn't detect, temporary fix |\n",
    "| **Smoothing** | 70-90% | ↓ 5-10% | High (50x slower) | Certified but expensive |\n",
    "| **Pruning** | 80-95% | ↓ 10-15% | Medium | May lose useful features |\n",
    "| **Ensemble** | 85-95% | ↓ small | High | Multiple models needed |\n",
    "\n",
    "### Deployment Strategy:\n",
    "\n",
    "**Recommended Approach:**\n",
    "1. **Prefer clean training data** from trusted sources\n",
    "2. **Combine defenses:** Fine-tuning + periodic auditing\n",
    "3. **For high-assurance:** Randomized smoothing with certified bounds\n",
    "4. **Detection via:** Activation clustering on suspicious subsets\n",
    "5. **Long-term:** Model signing and supply chain verification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52931c33",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Clustering Analysis (Medium)\n",
    "Experiment with different cluster counts in the activation clustering:\n",
    "- Try k=2, 3, 5, 10\n",
    "- Measure silhouette score for each\n",
    "- Which k best separates trojaned from clean samples?\n",
    "\n",
    "### Exercise 2: Layer-wise Fine-Tuning (Hard)\n",
    "Implement fine-tuning that updates different layers with different learning rates:\n",
    "- Early layers: lr=0.0001 (preserve features)\n",
    "- Middle layers: lr=0.001\n",
    "- Last layer: lr=0.01 (aggressive update)\n",
    "\n",
    "Does this improve trojan suppression while preserving clean accuracy?\n",
    "\n",
    "### Exercise 3: Smoothing Robustness Analysis (Hard)\n",
    "Test randomized smoothing with different noise levels (σ):\n",
    "- σ = 0.1, 0.3, 0.5, 0.7, 1.0\n",
    "- Measure clean accuracy and trojan suppression\n",
    "- Find the sweet spot where trojan is fully suppressed but accuracy preserved\n",
    "\n",
    "### Exercise 4: Ensemble Defense (Hard)\n",
    "Combine 5 independently fine-tuned models and take majority vote:\n",
    "- Does ensemble improve over single model?\n",
    "- What's the computational overhead?\n",
    "- Can you achieve >95% trojan suppression with minimal accuracy drop?\n",
    "\n",
    "### Exercise 5: Defense Evasion (Hard)\n",
    "Try to design a \"stealthy\" trojan that survives fine-tuning:\n",
    "- Distribute trojan across all layers (not just output)\n",
    "- Use input-dependent triggers that are semantic\n",
    "- Can you make a trojan that survives even 10 epochs of fine-tuning?\n",
    "\n",
    "### Exercise 6: Cost-Benefit Analysis (Hard)\n",
    "For a production ML system, calculate the ROI of defenses:\n",
    "- Cost of attack: trojan causes $1M in financial losses\n",
    "- Cost of defense: fine-tuning adds 5% latency, smoothing adds 50x\n",
    "- Which defense(s) is worth deploying?\n",
    "- Can you combine defenses to minimize cost while maximizing protection?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
