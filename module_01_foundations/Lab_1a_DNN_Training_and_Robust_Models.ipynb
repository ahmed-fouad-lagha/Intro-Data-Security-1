{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0de37f",
   "metadata": {},
   "source": [
    "# **Lab 1a: Deep Neural Network Training & Robust Models**\n",
    "\n",
    "**Course:** Introduction to Data Security Pr. (Master's Level)  \n",
    "**Module 1:** Foundations  \n",
    "**Estimated Time:** 90-120 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Train** deep neural networks on standard image classification datasets (MNIST, CIFAR-10)\n",
    "2. **Evaluate** model performance using standard metrics (accuracy, loss, confusion matrix)\n",
    "3. **Understand** the difference between standard models and robust models\n",
    "4. **Load** and compare pre-trained robust models\n",
    "5. **Analyze** vulnerability of standard models to adversarial perturbations\n",
    "6. **Establish** baseline models for subsequent security labs\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Setup & Imports](#setup)\n",
    "2. [Part 1: Dataset Loading & Preprocessing](#part1)\n",
    "3. [Part 2: Training a Standard CNN](#part2)\n",
    "4. [Part 3: Evaluating Model Performance](#part3)\n",
    "5. [Part 4: Understanding Robust Models](#part4)\n",
    "6. [Part 5: Loading Pre-trained Robust Models](#part5)\n",
    "7. [Part 6: Comparing Standard vs. Robust Models](#part6)\n",
    "8. [Exercises](#exercises)\n",
    "9. [Conclusion & Next Steps](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd653195",
   "metadata": {},
   "source": [
    "## **Setup & Imports** <a name=\"setup\"></a>\n",
    "\n",
    "First, we'll install necessary libraries and import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c841f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision matplotlib numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1029eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68fd0b",
   "metadata": {},
   "source": [
    "## **Part 1: Dataset Loading & Preprocessing** <a name=\"part1\"></a>\n",
    "\n",
    "We'll work with **MNIST** (handwritten digits) as our primary dataset. MNIST is a standard benchmark for:\n",
    "- Image classification\n",
    "- Neural network training\n",
    "- Adversarial robustness research\n",
    "\n",
    "**Dataset Details:**\n",
    "- **Training samples:** 60,000\n",
    "- **Test samples:** 10,000\n",
    "- **Image size:** 28×28 grayscale\n",
    "- **Classes:** 10 (digits 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff32d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor and scale to [0, 1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of batches (train): {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfc1e9",
   "metadata": {},
   "source": [
    "### **Visualize Sample Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfa359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training samples\n",
    "def show_images(dataset, num_samples=10):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image, label = dataset[i]\n",
    "        # Denormalize for visualization\n",
    "        image = image * 0.3081 + 0.1307\n",
    "        axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bec0cb",
   "metadata": {},
   "source": [
    "## **Part 2: Training a Standard CNN** <a name=\"part2\"></a>\n",
    "\n",
    "We'll implement a **Convolutional Neural Network (CNN)** architecture commonly used for MNIST classification.\n",
    "\n",
    "**Architecture:**\n",
    "- Conv Layer 1: 1 → 32 channels, 3×3 kernel\n",
    "- Conv Layer 2: 32 → 64 channels, 3×3 kernel\n",
    "- MaxPooling layers\n",
    "- Fully Connected layers\n",
    "- Dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9062822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardCNN(nn.Module):\n",
    "    \"\"\"Standard CNN architecture for MNIST classification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StandardCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = StandardCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a11b49",
   "metadata": {},
   "source": [
    "### **Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    \"\"\"Train the model and return training history.\"\"\"\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': []}\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "        \n",
    "        # Epoch statistics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65c59c",
   "metadata": {},
   "source": [
    "### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\\n\")\n",
    "history = train_model(model, train_loader, criterion, optimizer, device, epochs=5)\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db392915",
   "metadata": {},
   "source": [
    "### **Visualize Training Progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "ax1.plot(history['train_loss'], marker='o', color='red', linewidth=2)\n",
    "ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(history['train_acc'], marker='o', color='blue', linewidth=2)\n",
    "ax2.set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d886",
   "metadata": {},
   "source": [
    "## **Part 3: Evaluating Model Performance** <a name=\"part3\"></a>\n",
    "\n",
    "Now we'll evaluate our trained model on the test set using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set and return predictions.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "# Evaluate\n",
    "predictions, labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels, predictions, target_names=[str(i) for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce77c88",
   "metadata": {},
   "source": [
    "### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c524eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title('Confusion Matrix - Standard CNN on MNIST', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Class {i} accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830db99",
   "metadata": {},
   "source": [
    "### **Visualize Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correct and incorrect predictions\n",
    "def visualize_predictions(model, test_dataset, device, num_samples=10):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get random samples\n",
    "    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, i in enumerate(indices):\n",
    "        image, true_label = test_dataset[i]\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(image.unsqueeze(0).to(device))\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted_label = predicted.item()\n",
    "        \n",
    "        # Denormalize for visualization\n",
    "        img_display = image * 0.3081 + 0.1307\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx].imshow(img_display.squeeze(), cmap='gray')\n",
    "        color = 'green' if predicted_label == true_label else 'red'\n",
    "        axes[idx].set_title(f'True: {true_label}, Pred: {predicted_label}', color=color)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c4f15a",
   "metadata": {},
   "source": [
    "## **Part 4: Understanding Robust Models** <a name=\"part4\"></a>\n",
    "\n",
    "### **What Makes a Model \"Robust\"?**\n",
    "\n",
    "A **robust model** is one that maintains high accuracy even when inputs are perturbed. In adversarial machine learning:\n",
    "\n",
    "**Standard Models:**\n",
    "- Trained on clean data\n",
    "- Optimized for accuracy on unperturbed inputs\n",
    "- Vulnerable to adversarial perturbations\n",
    "- High clean accuracy but low adversarial accuracy\n",
    "\n",
    "**Robust Models:**\n",
    "- Trained with adversarial examples (adversarial training)\n",
    "- Optimized to resist perturbations\n",
    "- More resilient to attacks\n",
    "- Slightly lower clean accuracy but much higher adversarial accuracy\n",
    "\n",
    "### **Adversarial Training**\n",
    "\n",
    "The most effective defense against adversarial attacks:\n",
    "\n",
    "```python\n",
    "# Simplified adversarial training loop\n",
    "for batch in data_loader:\n",
    "    # 1. Generate adversarial examples\n",
    "    adv_examples = generate_adversarial(model, batch)\n",
    "    \n",
    "    # 2. Train on both clean and adversarial examples\n",
    "    loss_clean = criterion(model(batch), labels)\n",
    "    loss_adv = criterion(model(adv_examples), labels)\n",
    "    \n",
    "    total_loss = loss_clean + loss_adv\n",
    "    total_loss.backward()\n",
    "```\n",
    "\n",
    "### **Trade-offs**\n",
    "\n",
    "| Aspect | Standard Model | Robust Model |\n",
    "|--------|---------------|---------------|\n",
    "| Clean Accuracy | ~99% | ~95-97% |\n",
    "| Adversarial Accuracy | ~10-30% | ~70-85% |\n",
    "| Training Time | Fast | 5-10× slower |\n",
    "| Inference Time | Fast | Similar |\n",
    "| Model Complexity | Standard | Similar |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5848a6",
   "metadata": {},
   "source": [
    "## **Part 5: Saving & Loading Models** <a name=\"part5\"></a>\n",
    "\n",
    "We'll save our **standard** model and demonstrate how to load a saved model checkpoint.\n",
    "In later labs, you'll load **robust** checkpoints for side-by-side comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04345ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our trained standard model\n",
    "model_save_path = 'standard_mnist_cnn.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'accuracy': accuracy,\n",
    "    'history': history\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "def load_model(model_path, model_class, device):\n",
    "    \"\"\"Load a saved model.\"\"\"\n",
    "    model = model_class().to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model, checkpoint\n",
    "\n",
    "# Load our saved model\n",
    "loaded_model, checkpoint = load_model(model_save_path, StandardCNN, device)\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Saved model accuracy: {checkpoint['accuracy'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c7264",
   "metadata": {},
   "source": [
    "### **Model Comparison Framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison framework\n",
    "class ModelComparison:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def add_model(self, name, model):\n",
    "        \"\"\"Add a model to compare.\"\"\"\n",
    "        self.models[name] = model\n",
    "    \n",
    "    def evaluate_all(self, test_loader, device):\n",
    "        \"\"\"Evaluate all models.\"\"\"\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nEvaluating {name}...\")\n",
    "            predictions, labels = evaluate_model(model, test_loader, device)\n",
    "            accuracy = accuracy_score(labels, predictions)\n",
    "            self.results[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'predictions': predictions,\n",
    "                'labels': labels\n",
    "            }\n",
    "            print(f\"{name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    def plot_comparison(self):\n",
    "        \"\"\"Plot comparison of models.\"\"\"\n",
    "        names = list(self.results.keys())\n",
    "        accuracies = [self.results[name]['accuracy'] * 100 for name in names]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(names, accuracies, color=['blue', 'green', 'red'][:len(names)])\n",
    "        plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "        plt.title('Model Comparison on Clean MNIST Test Set', fontsize=14, fontweight='bold')\n",
    "        plt.ylim([0, 100])\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Initialize comparison\n",
    "comparison = ModelComparison()\n",
    "comparison.add_model('Standard CNN', model)\n",
    "comparison.evaluate_all(test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c19e7",
   "metadata": {},
   "source": [
    "## **Part 6: Comparing Standard vs. Robust Models** <a name=\"part6\"></a>\n",
    "\n",
    "In the next labs, we'll:\n",
    "1. Generate adversarial examples\n",
    "2. Test both standard and robust models\n",
    "3. Measure adversarial accuracy\n",
    "4. Understand the robustness-accuracy tradeoff\n",
    "\n",
    "**Preview: What We'll See**\n",
    "\n",
    "```\n",
    "Model Performance:\n",
    "                    Clean Accuracy | Adversarial Accuracy (ε=0.3)\n",
    "Standard CNN              98.5%    |        15.2%\n",
    "Robust CNN (AT)           96.8%    |        78.4%\n",
    "```\n",
    "\n",
    "This demonstrates the **security vs. accuracy tradeoff** fundamental to robust ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147935a",
   "metadata": {},
   "source": [
    "## **Exercises** <a name=\"exercises\"></a>\n",
    "\n",
    "Complete these exercises to reinforce your understanding:\n",
    "\n",
    "### **Exercise 1: Model Architecture (Easy)**\n",
    "Modify the `StandardCNN` architecture to:\n",
    "- Add one more convolutional layer\n",
    "- Increase the number of filters to 128 in the last conv layer\n",
    "- Train and compare performance\n",
    "\n",
    "**Question:** Does deeper architecture always improve accuracy?\n",
    "\n",
    "### **Exercise 2: CIFAR-10 Training (Medium)**\n",
    "Adapt this notebook to train on CIFAR-10 instead of MNIST:\n",
    "- CIFAR-10 has 3-channel RGB images (32×32)\n",
    "- Update the architecture accordingly\n",
    "- Compare training time and accuracy\n",
    "\n",
    "**Hint:** Change the first conv layer to accept 3 input channels.\n",
    "\n",
    "### **Exercise 3: Data Augmentation (Medium)**\n",
    "Add data augmentation to the training pipeline:\n",
    "```python\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "```\n",
    "\n",
    "**Question:** Does augmentation improve generalization?\n",
    "\n",
    "### **Exercise 4: Hyperparameter Tuning (Hard)**\n",
    "Experiment with different hyperparameters:\n",
    "- Learning rates: [0.0001, 0.001, 0.01]\n",
    "- Batch sizes: [32, 64, 128, 256]\n",
    "- Optimizers: [Adam, SGD, RMSprop]\n",
    "\n",
    "Create a comparison table showing the effect of each hyperparameter.\n",
    "\n",
    "### **Exercise 5: Model Interpretability (Hard)**\n",
    "Implement feature visualization:\n",
    "- Extract and visualize learned filters from conv layers\n",
    "- Create activation maps for specific test images\n",
    "- Analyze which features the model learns\n",
    "\n",
    "**Hint:** Use hooks to extract intermediate layer outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fcbc7",
   "metadata": {},
   "source": [
    "## **Conclusion & Next Steps** <a name=\"conclusion\"></a>\n",
    "---\n",
    "\n",
    "### **What You Learned**\n",
    "\n",
    "- **Neural Network Training:** Built and trained a CNN from scratch  \n",
    "- **Model Evaluation:** Used accuracy, confusion matrix, and classification reports  \n",
    "- **Robust Models:** Understood the concept of adversarial robustness  \n",
    "- **Model Persistence:** Saved and loaded trained models  \n",
    "- **Baseline Establishment:** Created standard models for future attack labs  \n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "1. **Standard models** achieve high clean accuracy but are vulnerable to adversarial attacks\n",
    "2. **Robust models** trade some clean accuracy for adversarial resilience\n",
    "3. **Adversarial training** is the most effective defense but computationally expensive\n",
    "4. **Model architecture** affects both performance and robustness\n",
    "\n",
    "### **Next Lab Preview**\n",
    "\n",
    "**Lab 1b: Threat Modeling & Attack Taxonomy**\n",
    "- Understand the adversarial threat landscape\n",
    "- Learn about different attack categories\n",
    "- Formalize security objectives and threat models\n",
    "- Prepare for implementing actual attacks\n",
    "\n",
    "### **Additional Resources**\n",
    "\n",
    "- **Paper:** [Explaining and Harnessing Adversarial Examples (Goodfellow et al., 2015)](https://arxiv.org/abs/1412.6572)\n",
    "- **Paper:** [Towards Deep Learning Models Resistant to Adversarial Attacks (Madry et al., 2018)](https://arxiv.org/abs/1706.06083)\n",
    "- **Library:** [Torchvision Models](https://pytorch.org/vision/stable/models.html)\n",
    "- **Tutorial:** [PyTorch Training Tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
