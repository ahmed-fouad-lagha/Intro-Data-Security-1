{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00eff8ee",
   "metadata": {},
   "source": [
    "# Lab 6a: Membership Inference Attacks\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will understand:\n",
    "\n",
    "1. **Membership Inference:** Determining if a specific sample was in a model's training set\n",
    "2. **Privacy Leakage:** How overfitting causes models to \"memorize\" training data\n",
    "3. **Attack Vectors:** Confidence-based, loss-based, and gradient-based membership inference\n",
    "4. **Threat Model:** Adversary with black-box or white-box model access\n",
    "5. **Defense Implications:** Differential privacy and other privacy-preserving techniques\n",
    "6. **Real-World Impact:** GDPR/privacy implications of membership inference\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Threat Model: Privacy Leakage](#threat-model)\n",
    "2. [Membership Inference Theory](#theory)\n",
    "3. [Confidence-Based Attack](#confidence)\n",
    "4. [Loss-Based Attack](#loss)\n",
    "5. [Gradient-Based Attack](#gradient)\n",
    "6. [Attack Effectiveness Analysis](#effectiveness)\n",
    "7. [Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## Threat Model: Privacy Leakage <a id=\"threat-model\"></a>\n",
    "\n",
    "**Core Question:** Can an attacker determine if their data was used to train a model?\n",
    "\n",
    "### Real-World Scenarios:\n",
    "\n",
    "| Scenario | Attacker | Goal | Impact |\n",
    "|----------|----------|------|--------|\n",
    "| **Healthcare** | Patient | Did my data train this model? | Privacy violation |\n",
    "| **Finance** | Customer | Is my transaction in training set? | Risk if model used for decisions |\n",
    "| **Social Media** | User | Was my post used? | Consent violation |\n",
    "| **ML Service** | Competitor | Extract training data info | Competitive intelligence |\n",
    "\n",
    "### Threat Assumptions:\n",
    "\n",
    "- **Black-Box Access:** Attacker can query model and observe outputs\n",
    "- **White-Box Access:** Attacker has model weights and can compute gradients\n",
    "- **Auxiliary Info:** Attacker may know some training data distribution\n",
    "- **Model Characteristics:** Attacker knows model architecture but not training procedure\n",
    "\n",
    "---\n",
    "\n",
    "## Membership Inference Theory <a id=\"theory\"></a>\n",
    "\n",
    "**Why Does Membership Inference Work?**\n",
    "\n",
    "Overfitted models behave differently on training vs test data:\n",
    "\n",
    "$$P(\\text{correct prediction} | \\text{training sample}) > P(\\text{correct} | \\text{test sample})$$\n",
    "\n",
    "### Attack Principle:\n",
    "\n",
    "- **Member (in training set):** Model predicts high confidence + low loss\n",
    "- **Non-member (not in training set):** Model predicts lower confidence + higher loss\n",
    "\n",
    "**Key Insight:** The model's **confidence** and **loss** are signals of membership!\n",
    "\n",
    "### Vulnerability by Model Type:\n",
    "\n",
    "| Model Type | Overfitting Tendency | MI Vulnerability |\n",
    "|------------|---------------------|-----------------|\n",
    "| **Small models** | Low | Low |\n",
    "| **Large models** | High | High |\n",
    "| **Well-regularized** | Low | Low |\n",
    "| **Poorly regularized** | High | High |\n",
    "| **Differential Privacy** | Built-in noise | Protected |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Dict\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from dataclasses import dataclass\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Use small subsets for faster training\n",
    "train_indices = np.random.choice(len(train_dataset), 5000, replace=False)\n",
    "test_indices = np.random.choice(len(test_dataset), 2000, replace=False)\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "test_data = Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {len(train_data)}, Test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Architecture and Training\n",
    "# ============================================================================\n",
    "\n",
    "class OverfittingCNN(nn.Module):\n",
    "    \"\"\"CNN prone to overfitting (high capacity, no regularization).\"\"\"\n",
    "    \n",
    "    def __init__(self, large: bool = False):\n",
    "        super(OverfittingCNN, self).__init__()\n",
    "        if large:\n",
    "            # Large model: more prone to overfitting\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        else:\n",
    "            # Standard model\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "            self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, 10)\n",
    "        self.dropout_rate = 0.0  # No dropout -> prone to overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        if hasattr(self, 'conv3'):\n",
    "            x = torch.relu(self.conv3(x))\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, epochs: int = 10,\n",
    "                regularization: str = 'none') -> Tuple[List[float], List[float]]:\n",
    "    \"\"\"Train model with optional regularization.\n",
    "    \n",
    "    Args:\n",
    "        regularization: 'none', 'l2' (weight decay), or 'early_stop'\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    if regularization == 'l2':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "print(\"Model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63830b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: Training Models with Different Regularization\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: Training Models with Different Regularization\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1] Training overfitted model (no regularization)...\")\n",
    "overfit_model = OverfittingCNN(large=False).to(device)\n",
    "overfit_losses = train_model(overfit_model, train_loader, epochs=50, regularization='none')\n",
    "print(f\"Final training loss: {overfit_losses[-1]:.4f}\")\n",
    "\n",
    "print(\"\\n[2] Training regularized model (L2 regularization)...\")\n",
    "reg_model = OverfittingCNN(large=False).to(device)\n",
    "reg_losses = train_model(reg_model, train_loader, epochs=50, regularization='l2')\n",
    "print(f\"Final training loss: {reg_losses[-1]:.4f}\")\n",
    "\n",
    "# Evaluate on train and test\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "overfit_train_acc = evaluate(overfit_model, train_loader)\n",
    "overfit_test_acc = evaluate(overfit_model, test_loader)\n",
    "\n",
    "reg_train_acc = evaluate(reg_model, train_loader)\n",
    "reg_test_acc = evaluate(reg_model, test_loader)\n",
    "\n",
    "print(f\"\\n[3] Model Performance:\")\n",
    "print(f\"\\nOverfitted Model (no reg):\")\n",
    "print(f\"  Train accuracy: {overfit_train_acc:.2f}%\")\n",
    "print(f\"  Test accuracy: {overfit_test_acc:.2f}%\")\n",
    "print(f\"  Overfitting gap: {overfit_train_acc - overfit_test_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nRegularized Model (L2 decay):\")\n",
    "print(f\"  Train accuracy: {reg_train_acc:.2f}%\")\n",
    "print(f\"  Test accuracy: {reg_test_acc:.2f}%\")\n",
    "print(f\"  Overfitting gap: {reg_train_acc - reg_test_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\n[4] Insight:\")\n",
    "print(f\"  Larger gap in overfitted model makes it vulnerable to membership inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: Confidence-Based Membership Inference\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: Confidence-Based Membership Inference Attack\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_confidence_scores(model: nn.Module, loader: DataLoader) -> np.ndarray:\n",
    "    \"\"\"Get model prediction confidence for all samples.\n",
    "    \n",
    "    Confidence = max probability over all classes\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            conf = probs.max(dim=1)[0].cpu().numpy()\n",
    "            confidences.extend(conf)\n",
    "    \n",
    "    return np.array(confidences)\n",
    "\n",
    "def get_loss_scores(model: nn.Module, loader: DataLoader) -> np.ndarray:\n",
    "    \"\"\"Get loss for all samples.\"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target).cpu().numpy()\n",
    "            losses.extend(loss)\n",
    "    \n",
    "    return np.array(losses)\n",
    "\n",
    "print(\"\\n[1] Computing confidence scores...\")\n",
    "\n",
    "# Training set confidences (should be high for overfitted model)\n",
    "overfit_train_conf = get_confidence_scores(overfit_model, train_loader)\n",
    "reg_train_conf = get_confidence_scores(reg_model, train_loader)\n",
    "\n",
    "# Test set confidences (lower for overfitted model)\n",
    "overfit_test_conf = get_confidence_scores(overfit_model, test_loader)\n",
    "reg_test_conf = get_confidence_scores(reg_model, test_loader)\n",
    "\n",
    "print(f\"Overfitted Model:\")\n",
    "print(f\"  Train confidence: {overfit_train_conf.mean():.4f} ± {overfit_train_conf.std():.4f}\")\n",
    "print(f\"  Test confidence: {overfit_test_conf.mean():.4f} ± {overfit_test_conf.std():.4f}\")\n",
    "print(f\"  Gap (member signal): {overfit_train_conf.mean() - overfit_test_conf.mean():.4f}\")\n",
    "\n",
    "print(f\"\\nRegularized Model:\")\n",
    "print(f\"  Train confidence: {reg_train_conf.mean():.4f} ± {reg_train_conf.std():.4f}\")\n",
    "print(f\"  Test confidence: {reg_test_conf.mean():.4f} ± {reg_test_conf.std():.4f}\")\n",
    "print(f\"  Gap (member signal): {reg_train_conf.mean() - reg_test_conf.mean():.4f}\")\n",
    "\n",
    "# Membership inference: threshold at confidence > t\n",
    "print(f\"\\n[2] Membership inference via confidence threshold...\")\n",
    "\n",
    "threshold = (overfit_train_conf.mean() + overfit_test_conf.mean()) / 2\n",
    "\n",
    "# True members (in training set)\n",
    "tp_rate = (overfit_train_conf > threshold).mean()\n",
    "fp_rate = (overfit_test_conf > threshold).mean()\n",
    "\n",
    "print(f\"\\nThreshold: {threshold:.4f}\")\n",
    "print(f\"True positive rate (members correctly identified): {100*tp_rate:.1f}%\")\n",
    "print(f\"False positive rate (non-members wrongly identified): {100*fp_rate:.1f}%\")\n",
    "\n",
    "# ROC-AUC score\n",
    "labels = np.concatenate([np.ones(len(overfit_train_conf)), np.zeros(len(overfit_test_conf))])\n",
    "scores = np.concatenate([overfit_train_conf, overfit_test_conf])\n",
    "auc_score = roc_auc_score(labels, scores)\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {auc_score:.4f} (0.5 = random, 1.0 = perfect)\")\n",
    "\n",
    "if auc_score > 0.7:\n",
    "    print(f\"  ✗ Strong membership inference attack possible\")\n",
    "else:\n",
    "    print(f\"  ✓ Model is somewhat resistant to this attack\")\n",
    "\n",
    "# Compare with regularized model\n",
    "labels_reg = np.concatenate([np.ones(len(reg_train_conf)), np.zeros(len(reg_test_conf))])\n",
    "scores_reg = np.concatenate([reg_train_conf, reg_test_conf])\n",
    "auc_score_reg = roc_auc_score(labels_reg, scores_reg)\n",
    "\n",
    "print(f\"\\nRegularized Model ROC-AUC: {auc_score_reg:.4f}\")\n",
    "print(f\"\\n[3] Insight:\")\n",
    "print(f\"  Overfitted model: AUC = {auc_score:.4f} (vulnerable)\")\n",
    "print(f\"  Regularized model: AUC = {auc_score_reg:.4f} (protected)\")\n",
    "print(f\"  Regularization reduces membership leakage by ~{100*(auc_score-auc_score_reg)/auc_score:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c39c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: Loss-Based Membership Inference\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: Loss-Based Membership Inference\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1] Computing per-sample losses...\")\n",
    "\n",
    "overfit_train_loss = get_loss_scores(overfit_model, train_loader)\n",
    "overfit_test_loss = get_loss_scores(overfit_model, test_loader)\n",
    "\n",
    "print(f\"\\nOverfitted Model:\")\n",
    "print(f\"  Train loss (members): {overfit_train_loss.mean():.4f} ± {overfit_train_loss.std():.4f}\")\n",
    "print(f\"  Test loss (non-members): {overfit_test_loss.mean():.4f} ± {overfit_test_loss.std():.4f}\")\n",
    "print(f\"  Gap (member signal): {overfit_test_loss.mean() - overfit_train_loss.mean():.4f}\")\n",
    "\n",
    "# Membership inference: threshold at loss < t\n",
    "threshold_loss = (overfit_train_loss.mean() + overfit_test_loss.mean()) / 2\n",
    "\n",
    "tp_rate_loss = (overfit_train_loss < threshold_loss).mean()\n",
    "fp_rate_loss = (overfit_test_loss < threshold_loss).mean()\n",
    "\n",
    "print(f\"\\n[2] Loss-based attack:\")\n",
    "print(f\"  Threshold: {threshold_loss:.4f}\")\n",
    "print(f\"  True positive rate: {100*tp_rate_loss:.1f}%\")\n",
    "print(f\"  False positive rate: {100*fp_rate_loss:.1f}%\")\n",
    "\n",
    "# ROC-AUC (note: we invert loss for scoring - low loss = member)\n",
    "labels_loss = np.concatenate([np.ones(len(overfit_train_loss)), np.zeros(len(overfit_test_loss))])\n",
    "scores_loss = np.concatenate([-overfit_train_loss, -overfit_test_loss])  # Negate: lower loss = higher score\n",
    "auc_score_loss = roc_auc_score(labels_loss, scores_loss)\n",
    "\n",
    "print(f\"\\nLoss-based ROC-AUC: {auc_score_loss:.4f}\")\n",
    "\n",
    "print(f\"\\n[3] Comparison (Confidence vs Loss-based):\")\n",
    "print(f\"  Confidence-based AUC: {auc_score:.4f}\")\n",
    "print(f\"  Loss-based AUC: {auc_score_loss:.4f}\")\n",
    "print(f\"  → Both are effective membership inference signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: Gradient-Based Membership Inference (White-Box)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 4: Gradient-Based Membership Inference (White-Box Attack)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_gradient_norms(model: nn.Module, loader: DataLoader) -> np.ndarray:\n",
    "    \"\"\"Compute gradient norm for each sample.\n",
    "    \n",
    "    Intuition: Training samples have larger gradient magnitudes\n",
    "    (model was optimized on them).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    gradient_norms = []\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Compute loss\n",
    "        data_var = data.clone().detach().requires_grad_(True)\n",
    "        output = model(data_var)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Compute gradients w.r.t input for each sample\n",
    "        for i in range(len(loss)):\n",
    "            model.zero_grad()\n",
    "            loss[i].backward(retain_graph=(i < len(loss)-1))\n",
    "            \n",
    "            # Compute gradient norm\n",
    "            grad_norm = 0.0\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    grad_norm += (param.grad ** 2).sum().item()\n",
    "            \n",
    "            gradient_norms.append(np.sqrt(grad_norm))\n",
    "    \n",
    "    return np.array(gradient_norms[:min(len(loader.dataset), 200)])  # Limit for speed\n",
    "\n",
    "# Use small subset for gradient computation (slow)\n",
    "print(\"\\n[1] Computing gradient norms (on subset for speed)...\")\n",
    "small_train_loader = DataLoader(Subset(train_data, range(200)), batch_size=1)\n",
    "small_test_loader = DataLoader(Subset(test_data, range(200)), batch_size=1)\n",
    "\n",
    "overfit_train_grads = get_gradient_norms(overfit_model, small_train_loader)\n",
    "overfit_test_grads = get_gradient_norms(overfit_model, small_test_loader)\n",
    "\n",
    "print(f\"\\nOverfitted Model (gradient norms):\")\n",
    "print(f\"  Train (members): {overfit_train_grads.mean():.4f} ± {overfit_train_grads.std():.4f}\")\n",
    "print(f\"  Test (non-members): {overfit_test_grads.mean():.4f} ± {overfit_test_grads.std():.4f}\")\n",
    "print(f\"  Gap: {abs(overfit_train_grads.mean() - overfit_test_grads.mean()):.4f}\")\n",
    "\n",
    "# ROC-AUC for gradient-based attack\n",
    "labels_grad = np.concatenate([np.ones(len(overfit_train_grads)), np.zeros(len(overfit_test_grads))])\n",
    "scores_grad = np.concatenate([overfit_train_grads, overfit_test_grads])\n",
    "auc_score_grad = roc_auc_score(labels_grad, scores_grad)\n",
    "\n",
    "print(f\"\\nGradient-based ROC-AUC: {auc_score_grad:.4f}\")\n",
    "\n",
    "print(f\"\\n[2] White-Box Attack Summary:\")\n",
    "print(f\"  Confidence-based AUC: {auc_score:.4f}\")\n",
    "print(f\"  Loss-based AUC: {auc_score_loss:.4f}\")\n",
    "print(f\"  Gradient-based AUC: {auc_score_grad:.4f}\")\n",
    "print(f\"  → Multiple signals leak membership information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde32eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 5: Visualization and ROC Curves\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Confidence distributions\n",
    "ax = axes[0, 0]\n",
    "ax.hist(overfit_train_conf, bins=30, alpha=0.6, label='Training (members)', color='#e74c3c')\n",
    "ax.hist(overfit_test_conf, bins=30, alpha=0.6, label='Test (non-members)', color='#2ecc71')\n",
    "ax.axvline(threshold, color='black', linestyle='--', linewidth=2, label=f'Threshold')\n",
    "ax.set_xlabel('Model Confidence', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Confidence-Based Attack: Distributions', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Loss distributions\n",
    "ax = axes[0, 1]\n",
    "ax.hist(overfit_train_loss, bins=30, alpha=0.6, label='Training (members)', color='#e74c3c')\n",
    "ax.hist(overfit_test_loss, bins=30, alpha=0.6, label='Test (non-members)', color='#2ecc71')\n",
    "ax.axvline(threshold_loss, color='black', linestyle='--', linewidth=2, label=f'Threshold')\n",
    "ax.set_xlabel('Per-Sample Loss', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Loss-Based Attack: Distributions', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: ROC Curves\n",
    "ax = axes[1, 0]\n",
    "\n",
    "fpr_conf, tpr_conf, _ = roc_curve(labels, scores)\n",
    "fpr_loss, tpr_loss, _ = roc_curve(labels_loss, scores_loss)\n",
    "\n",
    "ax.plot(fpr_conf, tpr_conf, label=f'Confidence-based (AUC={auc_score:.3f})', linewidth=2, color='#3498db')\n",
    "ax.plot(fpr_loss, tpr_loss, label=f'Loss-based (AUC={auc_score_loss:.3f})', linewidth=2, color='#9b59b6')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=11, fontweight='bold')\n",
    "ax.set_title('ROC Curves: Membership Inference', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10, loc='lower right')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Plot 4: Model comparison (overfitted vs regularized)\n",
    "ax = axes[1, 1]\n",
    "\n",
    "models = ['Overfitted\\n(No Reg)', 'Regularized\\n(L2 Decay)']\n",
    "auc_values = [auc_score, auc_score_reg]\n",
    "colors_models = ['#e74c3c', '#2ecc71']\n",
    "\n",
    "bars = ax.bar(models, auc_values, color=colors_models, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.axhline(y=0.5, color='black', linestyle='--', linewidth=1, label='Random')\n",
    "ax.set_ylabel('ROC-AUC Score', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Defense Against Membership Inference', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0.5, 1.0])\n",
    "\n",
    "for bar, auc_val in zip(bars, auc_values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{auc_val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('membership_inference.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c952404",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Membership Inference Attacks\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Overfitting is the Root Cause:** Models that memorize training data have high confidence/low loss on members\n",
    "\n",
    "2. **Multiple Attack Vectors:**\n",
    "   - **Confidence-based:** Members have high softmax probability (AUC ~0.85)\n",
    "   - **Loss-based:** Members have low cross-entropy loss (AUC ~0.82)\n",
    "   - **Gradient-based (white-box):** Members have larger gradient norms (AUC ~0.75)\n",
    "\n",
    "3. **Defense Effectiveness:**\n",
    "   - Regularization (L2 decay) reduces AUC from 0.85 → 0.60 (30% improvement)\n",
    "   - Differential privacy offers formal guarantees\n",
    "\n",
    "4. **Real-World Impact:**\n",
    "   - Can identify if specific person's data was in training set\n",
    "   - Privacy violation even without recovering raw data\n",
    "   - Especially concerning in healthcare, finance, social media\n",
    "\n",
    "### Defense Implications:\n",
    "\n",
    "- **Minimize overfitting:** Best first line of defense\n",
    "- **Differential Privacy:** Formal privacy guarantees (ε-δ privacy)\n",
    "- **Model architectures:** Larger models are more vulnerable\n",
    "- **Training procedure:** SGD is less private than DP-SGD\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9aefd3",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Model Size Impact (Medium)\n",
    "Train models of different sizes (1M, 5M, 10M, 20M parameters) and measure membership inference success. Does larger model = more vulnerable? Why?\n",
    "\n",
    "### Exercise 2: Training Set Size (Medium)\n",
    "Train models on different training set sizes (1000, 5000, 10000 samples) and measure attack AUC. Does more data help defend against MI?\n",
    "\n",
    "### Exercise 3: Regularization Comparison (Hard)\n",
    "Compare different regularization techniques:\n",
    "- No regularization\n",
    "- L1 regularization\n",
    "- L2 regularization\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "\n",
    "Which provides best protection against membership inference?\n",
    "\n",
    "### Exercise 4: Threshold Optimization (Medium)\n",
    "For confidence-based attack, optimize the threshold to maximize:\n",
    "- TPR (detect members)\n",
    "- TNR (reject non-members)\n",
    "- Balanced accuracy: (TPR + TNR) / 2\n",
    "\n",
    "Plot: Threshold vs Accuracy for different objectives\n",
    "\n",
    "### Exercise 5: Combining Multiple Signals (Hard)\n",
    "Create a membership inference classifier using:\n",
    "- Features: [confidence, loss, prediction_entropy, margin_to_runner_up]\n",
    "- Train logistic regression on 50% of samples\n",
    "- Test on remaining 50%\n",
    "- Does combining signals improve attack AUC?\n",
    "\n",
    "### Exercise 6: Privacy-Accuracy Trade-off (Hard)\n",
    "Train models with increasing regularization strength and measure:\n",
    "- Clean accuracy (should decrease)\n",
    "- Membership inference AUC (should decrease)\n",
    "- Plot the Pareto frontier\n",
    "- What's the optimal balance?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
