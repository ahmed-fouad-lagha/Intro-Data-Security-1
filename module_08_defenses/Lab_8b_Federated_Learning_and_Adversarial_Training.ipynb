{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fba13e",
   "metadata": {},
   "source": [
    "# Lab 8b: Federated Learning and Adversarial Training\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will understand:\n",
    "\n",
    "1. **Federated Learning (FL):** Training without centralizing data\n",
    "2. **FedAvg Algorithm:** Aggregating model updates across clients\n",
    "3. **Privacy & Security Benefits:** Data locality, attack surface reduction\n",
    "4. **Adversarial Training:** Robustness against evasion attacks\n",
    "5. **Combined Defenses:** FL + adversarial training for stronger guarantees\n",
    "6. **Practical Challenges:** Non-IID data, client drift, communication costs\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Threat Model & Rationale](#threat-model)\n",
    "2. [Federated Learning (FedAvg)](#fl)\n",
    "3. [Adversarial Training (FGSM)](#adv-training)\n",
    "4. [Robustness Evaluation](#evaluation)\n",
    "5. [Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## Threat Model & Rationale <a id=\"threat-model\"></a>\n",
    "\n",
    "**Why FL?** Data is sensitive, so it remains on client devices.\n",
    "\n",
    "### Threats Addressed:\n",
    "\n",
    "| Threat | Defense | Mechanism |\n",
    "|--------|---------|-----------|\n",
    "| Data Exfiltration | FL | No raw data leaves device |\n",
    "| Membership Inference | FL + DP | Aggregate updates only |\n",
    "| Evasion Attacks | Adversarial Training | Train on adversarial examples |\n",
    "| Data Poisoning | Robust Aggregation (optional) | Trimmed mean, Krum |\n",
    "\n",
    "### FL + Adversarial Training:\n",
    "- FL reduces data exposure\n",
    "- Adversarial training increases robustness to input attacks\n",
    "- Combined defenses create layered security\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Subset for speed\n",
    "train_indices = np.random.choice(len(train_dataset), 8000, replace=False)\n",
    "test_indices = np.random.choice(len(test_dataset), 2000, replace=False)\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "test_data = Subset(test_dataset, test_indices)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2565ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Definition\n",
    "# ============================================================================\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "print(\"Model ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e398b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: Federated Learning (FedAvg)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: Federated Learning (FedAvg)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_clients(dataset, n_clients=5, non_iid=False):\n",
    "    \"\"\"Split dataset into client subsets (IID or non-IID).\"\"\"\n",
    "    indices = np.arange(len(dataset))\n",
    "    if non_iid:\n",
    "        # Sort by labels to create non-IID splits\n",
    "        labels = np.array([dataset[i][1] for i in indices])\n",
    "        indices = indices[np.argsort(labels)]\n",
    "    \n",
    "    client_splits = np.array_split(indices, n_clients)\n",
    "    clients = [Subset(dataset, split) for split in client_splits]\n",
    "    return clients\n",
    "\n",
    "def local_train(model, loader, epochs=1, lr=0.01):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def federated_average(models):\n",
    "    \"\"\"FedAvg: average model parameters.\"\"\"\n",
    "    avg_model = SmallCNN().to(device)\n",
    "    \n",
    "    # Initialize with zeros\n",
    "    for param in avg_model.parameters():\n",
    "        param.data.zero_()\n",
    "    \n",
    "    # Average parameters\n",
    "    for model in models:\n",
    "        for avg_param, param in zip(avg_model.parameters(), model.parameters()):\n",
    "            avg_param.data += param.data / len(models)\n",
    "    \n",
    "    return avg_model\n",
    "\n",
    "# Create clients\n",
    "clients = create_clients(train_data, n_clients=5, non_iid=True)\n",
    "client_loaders = [DataLoader(c, batch_size=64, shuffle=True) for c in clients]\n",
    "\n",
    "print(f\"Created {len(clients)} clients.\")\n",
    "\n",
    "# Federated training\n",
    "global_model = SmallCNN().to(device)\n",
    "rounds = 5\n",
    "global_accuracies = []\n",
    "\n",
    "for r in range(rounds):\n",
    "    local_models = []\n",
    "    for loader in client_loaders:\n",
    "        local_model = SmallCNN().to(device)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_train(local_model, loader, epochs=1)\n",
    "        local_models.append(local_model)\n",
    "    \n",
    "    global_model = federated_average(local_models)\n",
    "    acc = evaluate(global_model, test_loader)\n",
    "    global_accuracies.append(acc)\n",
    "    print(f\"Round {r+1}/{rounds}: Global Test Accuracy = {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: Adversarial Training (FGSM)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: Adversarial Training (FGSM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def fgsm_attack(model, data, target, epsilon=0.1):\n",
    "    data.requires_grad = True\n",
    "    output = model(data)\n",
    "    loss = nn.CrossEntropyLoss()(output, target)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = data.grad.data\n",
    "    perturbed = data + epsilon * data_grad.sign()\n",
    "    return torch.clamp(perturbed, -3, 3)  # normalized range\n",
    "\n",
    "def adversarial_train(model, loader, epochs=3, epsilon=0.1):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Create adversarial examples\n",
    "            adv_data = fgsm_attack(model, data, target, epsilon=epsilon)\n",
    "            # Train on adversarial + clean mixed\n",
    "            optimizer.zero_grad()\n",
    "            output = model(adv_data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Adversarial training complete\")\n",
    "\n",
    "def evaluate_adversarial(model, loader, epsilon=0.1):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        adv_data = fgsm_attack(model, data, target, epsilon=epsilon)\n",
    "        output = model(adv_data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += target.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "# Train adversarial model (centralized for comparison)\n",
    "adv_model = SmallCNN().to(device)\n",
    "adv_train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "adversarial_train(adv_model, adv_train_loader, epochs=3, epsilon=0.1)\n",
    "\n",
    "clean_acc = evaluate(adv_model, test_loader)\n",
    "adv_acc = evaluate_adversarial(adv_model, test_loader, epsilon=0.1)\n",
    "\n",
    "print(f\"\\nAdversarially Trained Model:\")\n",
    "print(f\"  Clean Accuracy: {clean_acc:.2f}%\")\n",
    "print(f\"  Adversarial Accuracy (FGSM): {adv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ffbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: Combined Defense Comparison\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: Defense Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Baseline model (centralized training for comparison)\n",
    "baseline_model = SmallCNN().to(device)\n",
    "baseline_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "optimizer = optim.SGD(baseline_model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for _ in range(3):\n",
    "    for data, target in baseline_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = baseline_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "baseline_clean = evaluate(baseline_model, test_loader)\n",
    "baseline_adv = evaluate_adversarial(baseline_model, test_loader, epsilon=0.1)\n",
    "\n",
    "fedavg_clean = evaluate(global_model, test_loader)\n",
    "fedavg_adv = evaluate_adversarial(global_model, test_loader, epsilon=0.1)\n",
    "\n",
    "adv_clean = clean_acc\n",
    "adv_adv = adv_acc\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Model': ['Baseline', 'FedAvg', 'Adv Training'],\n",
    "    'Clean Acc': [baseline_clean, fedavg_clean, adv_clean],\n",
    "    'FGSM Acc': [baseline_adv, fedavg_adv, adv_adv]\n",
    "})\n",
    "\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: Visualization\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# FedAvg convergence\n",
    "ax = axes[0]\n",
    "ax.plot(global_accuracies, marker='o', linewidth=2, color='#3498db')\n",
    "ax.set_xlabel('Federated Round')\n",
    "ax.set_ylabel('Test Accuracy (%)')\n",
    "ax.set_title('FedAvg Convergence')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Robustness comparison\n",
    "ax = axes[1]\n",
    "x_pos = np.arange(len(summary))\n",
    "width = 0.35\n",
    "ax.bar(x_pos - width/2, summary['Clean Acc'], width, label='Clean', color='#2ecc71', alpha=0.8)\n",
    "ax.bar(x_pos + width/2, summary['FGSM Acc'], width, label='FGSM', color='#e74c3c', alpha=0.8)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(summary['Model'])\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Robustness Comparison')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('federated_adversarial.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('âœ“ Visualization complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59d5d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Federated Learning and Adversarial Training\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **FedAvg achieves strong utility** without sharing raw data\n",
    "2. **Non-IID data slows convergence** (client drift)\n",
    "3. **Adversarial training improves robustness** (higher FGSM accuracy)\n",
    "4. **Combined defenses provide layered security**\n",
    "\n",
    "### Practical Guidance:\n",
    "- **FL for privacy:** Use when data cannot leave devices\n",
    "- **Adversarial training for robustness:** Use when evasion attacks are a threat\n",
    "- **Combine with DP:** For formal privacy guarantees\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b315c6",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Non-IID Severity (Medium)\n",
    "Increase non-IID skew and measure FedAvg convergence degradation.\n",
    "\n",
    "### Exercise 2: Client Participation (Medium)\n",
    "Use partial participation (e.g., 50% clients per round). Compare accuracy.\n",
    "\n",
    "### Exercise 3: Robust Aggregation (Hard)\n",
    "Implement trimmed mean or Krum to defend against malicious clients.\n",
    "\n",
    "### Exercise 4: Adversarial Training in FL (Hard)\n",
    "Train each client with FGSM examples and compare global robustness.\n",
    "\n",
    "### Exercise 5: Communication Efficiency (Hard)\n",
    "Simulate gradient compression (top-k or quantization) and measure accuracy loss.\n",
    "\n",
    "### Exercise 6: Privacy-Utility Trade-off (Hard)\n",
    "Combine FL + DP + adversarial training. Evaluate privacy and robustness together."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
