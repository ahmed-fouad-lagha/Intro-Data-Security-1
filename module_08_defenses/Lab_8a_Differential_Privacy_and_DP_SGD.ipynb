{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772ba12e",
   "metadata": {},
   "source": [
    "# Lab 8a: Differential Privacy and DP-SGD\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will understand:\n",
    "\n",
    "1. **Differential Privacy (DP):** Formal privacy guarantees for ML\n",
    "2. **DP-SGD:** Gradient clipping + noise injection\n",
    "3. **Privacy Budget (ε, δ):** How to measure privacy loss\n",
    "4. **Utility Trade-offs:** Privacy vs model accuracy\n",
    "5. **Privacy Attacks:** Membership inference risk reduction\n",
    "6. **Real-World Deployment:** DP in regulated environments\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [DP Theory and Threat Model](#theory)\n",
    "2. [Baseline Training](#baseline)\n",
    "3. [DP-SGD Implementation](#dpsgd)\n",
    "4. [Privacy Accounting](#privacy)\n",
    "5. [Membership Inference Evaluation](#mia)\n",
    "6. [Exercises](#exercises)\n",
    "\n",
    "---\n",
    "\n",
    "## DP Theory and Threat Model <a id=\"theory\"></a>\n",
    "\n",
    "**Threat Model:** Adversary tries to determine if a record was in training data.\n",
    "\n",
    "### Differential Privacy Definition\n",
    "\n",
    "A randomized algorithm $A$ is $(ε, δ)$-differentially private if for all datasets $D, D'$\n",
    "differing in one record, and all outputs $S$:\n",
    "\n",
    "$$P[A(D) n S] e e^{ε} P[A(D') n S] + δ$$\n",
    "\n",
    "- **Lower ε:** Stronger privacy\n",
    "- **Lower δ:** Lower probability of privacy failure\n",
    "\n",
    "### DP-SGD Core Mechanism\n",
    "\n",
    "1. Compute per-sample gradients\n",
    "2. Clip gradient norm to $C$\n",
    "3. Add Gaussian noise $athcal{N}(0, σ^2 C^2)$\n",
    "4. Update model with noisy averaged gradient\n",
    "\n",
    "**Key Trade-off:** Higher noise (σ) → more privacy, less utility.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aaff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Subset for speed\n",
    "train_indices = np.random.choice(len(train_dataset), 6000, replace=False)\n",
    "test_indices = np.random.choice(len(test_dataset), 2000, replace=False)\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "test_data = Subset(test_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Definition\n",
    "# ============================================================================\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "print(\"Model ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9660db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: Baseline Training (No DP)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: Baseline Training\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def train_baseline(model, loader, epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        losses.append(epoch_loss / len(loader))\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Loss={losses[-1]:.4f}\")\n",
    "    return losses\n",
    "\n",
    "baseline_model = SmallCNN()\n",
    "baseline_losses = train_baseline(baseline_model, train_loader, epochs=5)\n",
    "\n",
    "baseline_train_acc = evaluate(baseline_model, train_loader)\n",
    "baseline_test_acc = evaluate(baseline_model, test_loader)\n",
    "\n",
    "print(f\"\\nBaseline Accuracy:\")\n",
    "print(f\"  Train: {baseline_train_acc:.2f}%\")\n",
    "print(f\"  Test:  {baseline_test_acc:.2f}%\")\n",
    "print(f\"  Overfitting Gap: {baseline_train_acc - baseline_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789aaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: DP-SGD Implementation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: DP-SGD Training\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "@dataclass\n",
    "class DPConfig:\n",
    "    clip_norm: float = 1.0\n",
    "    noise_multiplier: float = 1.0  # σ\n",
    "    epochs: int = 5\n",
    "    batch_size: int = 64\n",
    "\n",
    "def dp_sgd_step(model, data, target, config: DPConfig):\n",
    "    \"\"\"Single DP-SGD step with per-sample gradient clipping + noise.\"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    batch_size = data.size(0)\n",
    "    \n",
    "    # Compute per-sample gradients\n",
    "    per_sample_grads = []\n",
    "    for i in range(batch_size):\n",
    "        model.zero_grad()\n",
    "        output = model(data[i:i+1])\n",
    "        loss = criterion(output, target[i:i+1]).mean()\n",
    "        loss.backward()\n",
    "        grads = [p.grad.detach().clone() for p in model.parameters()]\n",
    "        per_sample_grads.append(grads)\n",
    "    \n",
    "    # Clip per-sample gradients\n",
    "    clipped_grads = []\n",
    "    for grads in per_sample_grads:\n",
    "        total_norm = torch.sqrt(sum((g**2).sum() for g in grads))\n",
    "        clip_factor = min(1.0, config.clip_norm / (total_norm + 1e-6))\n",
    "        clipped = [g * clip_factor for g in grads]\n",
    "        clipped_grads.append(clipped)\n",
    "    \n",
    "    # Aggregate clipped gradients\n",
    "    agg_grads = []\n",
    "    for param_i in range(len(clipped_grads[0])):\n",
    "        stacked = torch.stack([g[param_i] for g in clipped_grads], dim=0)\n",
    "        agg = stacked.mean(dim=0)\n",
    "        agg_grads.append(agg)\n",
    "    \n",
    "    # Add noise\n",
    "    noisy_grads = []\n",
    "    for g in agg_grads:\n",
    "        noise = torch.randn_like(g) * (config.noise_multiplier * config.clip_norm / batch_size)\n",
    "        noisy_grads.append(g + noise)\n",
    "    \n",
    "    # Apply gradients\n",
    "    for param, grad in zip(model.parameters(), noisy_grads):\n",
    "        param.grad = grad\n",
    "\n",
    "def train_dp_sgd(model, loader, config: DPConfig):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    losses = []\n",
    "    for epoch in range(config.epochs):\n",
    "        epoch_loss = 0\n",
    "        for data, target in loader:\n",
    "            optimizer.zero_grad()\n",
    "            dp_sgd_step(model, data, target, config)\n",
    "            optimizer.step()\n",
    "            # Compute loss for logging\n",
    "            output = model(data.to(device))\n",
    "            loss = nn.CrossEntropyLoss()(output, target.to(device))\n",
    "            epoch_loss += loss.item()\n",
    "        losses.append(epoch_loss / len(loader))\n",
    "        print(f\"Epoch {epoch+1}/{config.epochs}: Loss={losses[-1]:.4f}\")\n",
    "    return losses\n",
    "\n",
    "dp_config = DPConfig(clip_norm=1.0, noise_multiplier=1.0, epochs=5)\n",
    "dp_model = SmallCNN().to(device)\n",
    "dp_losses = train_dp_sgd(dp_model, train_loader, dp_config)\n",
    "\n",
    "dp_train_acc = evaluate(dp_model, train_loader)\n",
    "dp_test_acc = evaluate(dp_model, test_loader)\n",
    "\n",
    "print(f\"\\nDP-SGD Accuracy:\")\n",
    "print(f\"  Train: {dp_train_acc:.2f}%\")\n",
    "print(f\"  Test:  {dp_test_acc:.2f}%\")\n",
    "print(f\"  Overfitting Gap: {dp_train_acc - dp_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: Privacy Accounting (Approximate)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: Privacy Accounting\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def approximate_epsilon(steps, sample_rate, noise_multiplier, delta=1e-5):\n",
    "    \"\"\"Approximate privacy loss (ε) using a simplified bound.\n",
    "    \n",
    "    This is a pedagogical approximation, not production-grade.\n",
    "    \"\"\"\n",
    "    if noise_multiplier == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Heuristic: epsilon ~ sqrt(2 * steps * log(1/delta)) * sample_rate / noise_multiplier\n",
    "    eps = np.sqrt(2 * steps * np.log(1/delta)) * sample_rate / noise_multiplier\n",
    "    return eps\n",
    "\n",
    "steps = dp_config.epochs * len(train_loader)\n",
    "sample_rate = dp_config.batch_size / len(train_data)\n",
    "epsilon = approximate_epsilon(steps, sample_rate, dp_config.noise_multiplier, delta=1e-5)\n",
    "\n",
    "print(f\"Approximate privacy budget (ε, δ):\")\n",
    "print(f\"  ε ≈ {epsilon:.3f}, δ = 1e-5\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  Lower ε => stronger privacy, but lower utility\")\n",
    "print(f\"  Increase noise_multiplier to reduce ε\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: Membership Inference Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 4: Membership Inference Attack\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_confidences(model, loader):\n",
    "    model.eval()\n",
    "    confs = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            confs.extend(probs.max(dim=1)[0].cpu().numpy())\n",
    "    return np.array(confs)\n",
    "\n",
    "# Baseline model MIA\n",
    "baseline_train_conf = get_confidences(baseline_model, train_loader)\n",
    "baseline_test_conf = get_confidences(baseline_model, test_loader)\n",
    "\n",
    "labels_base = np.concatenate([np.ones(len(baseline_train_conf)), np.zeros(len(baseline_test_conf))])\n",
    "scores_base = np.concatenate([baseline_train_conf, baseline_test_conf])\n",
    "auc_base = roc_auc_score(labels_base, scores_base)\n",
    "\n",
    "# DP model MIA\n",
    "dp_train_conf = get_confidences(dp_model, train_loader)\n",
    "dp_test_conf = get_confidences(dp_model, test_loader)\n",
    "\n",
    "labels_dp = np.concatenate([np.ones(len(dp_train_conf)), np.zeros(len(dp_test_conf))])\n",
    "scores_dp = np.concatenate([dp_train_conf, dp_test_conf])\n",
    "auc_dp = roc_auc_score(labels_dp, scores_dp)\n",
    "\n",
    "print(f\"\\nMembership Inference AUC:\")\n",
    "print(f\"  Baseline model: {auc_base:.4f}\")\n",
    "print(f\"  DP-SGD model:  {auc_dp:.4f}\")\n",
    "print(f\"\\nPrivacy Improvement: {100*(auc_base-auc_dp)/auc_base:.1f}% reduction in attack AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45375501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 5: Visualization\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Plot 1: Training losses\n",
    "ax = axes[0]\n",
    "ax.plot(baseline_losses, label='Baseline', linewidth=2, color='#e74c3c')\n",
    "ax.plot(dp_losses, label='DP-SGD', linewidth=2, color='#3498db')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "ax = axes[1]\n",
    "accs = [baseline_test_acc, dp_test_acc]\n",
    "ax.bar(['Baseline', 'DP-SGD'], accs, color=['#e74c3c', '#3498db'], alpha=0.8)\n",
    "ax.set_ylabel('Test Accuracy (%)')\n",
    "ax.set_title('Utility Trade-off')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: MIA AUC\n",
    "ax = axes[2]\n",
    "aucs = [auc_base, auc_dp]\n",
    "ax.bar(['Baseline', 'DP-SGD'], aucs, color=['#e74c3c', '#3498db'], alpha=0.8)\n",
    "ax.set_ylabel('Membership Inference AUC')\n",
    "ax.set_title('Privacy Improvement')\n",
    "ax.set_ylim([0.5, 1.0])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dp_sgd_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Visualization complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf027852",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Differential Privacy and DP-SGD\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **DP-SGD reduces membership inference:** AUC drops from ~0.80 to ~0.60\n",
    "2. **Privacy-utility trade-off:** 3-8% accuracy reduction for significant privacy gain\n",
    "3. **Noise multiplier controls ε:** Larger noise → smaller ε (stronger privacy)\n",
    "4. **Clipping prevents outlier leakage:** Per-sample clipping limits gradient sensitivity\n",
    "\n",
    "### Practical Guidance:\n",
    "- **Regulated data (healthcare/finance):** Use DP-SGD with ε < 5\n",
    "- **Low-stakes data:** ε 5-10 is often acceptable\n",
    "- **Monitor membership inference AUC:** If AUC > 0.6, privacy risk remains\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45222a",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Noise vs Utility (Medium)\n",
    "Sweep noise_multiplier in [0.5, 1.0, 2.0, 4.0]. Plot test accuracy vs ε.\n",
    "\n",
    "### Exercise 2: Clip Norm Sensitivity (Medium)\n",
    "Try clip_norm values [0.5, 1.0, 2.0]. Which gives best privacy-utility balance?\n",
    "\n",
    "### Exercise 3: DP-SGD on Larger Model (Hard)\n",
    "Apply DP-SGD to a larger CNN and evaluate privacy loss and utility.\n",
    "\n",
    "### Exercise 4: Attack Transfer (Hard)\n",
    "Try loss-based membership inference and compare against confidence-based.\n",
    "\n",
    "### Exercise 5: Privacy Accounting (Hard)\n",
    "Implement a more accurate accountant (RDP) or use Opacus. Compare ε values.\n",
    "\n",
    "### Exercise 6: DP in Practice (Hard)\n",
    "Design DP parameters for a healthcare dataset with target test accuracy ≥ 95%."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
