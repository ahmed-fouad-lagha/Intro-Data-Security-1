{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1427af19",
   "metadata": {},
   "source": [
    "# **Lab 3b: Data Poisoning Attacks (Backdoor & Trigger Injection)**\n",
    "\n",
    "**Course:** Introduction to Data Security Pr.  \n",
    "**Module 3:** Integrity Attacks - Data Poisoning  \n",
    "**Estimated Time:** 120 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Design** and inject backdoor triggers into training data\n",
    "2. **Implement** patch-based and pattern-based triggers\n",
    "3. **Measure** backdoor success rate and stealthiness\n",
    "4. **Analyze** trigger transferability across models\n",
    "5. **Develop** defenses against backdoor attacks\n",
    "\n",
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Setup & Imports](#setup)\n",
    "2. [Patch-Based Backdoor](#patch)\n",
    "3. [Pattern-Based Backdoor](#pattern)\n",
    "4. [Backdoor Success Rate](#success)\n",
    "5. [Defense Strategies](#defense)\n",
    "6. [Exercises](#exercises)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79d33c",
   "metadata": {},
   "source": [
    "## **Setup & Imports** <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fc50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72192d",
   "metadata": {},
   "source": [
    "## **Patch-Based Backdoor** <a name=\"patch\"></a>\n",
    "\n",
    "Inject a small patch (e.g., white square) in the corner of images.\n",
    "When trigger is present, model outputs target class regardless of true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patch_trigger(image, patch_size=4, patch_value=1.0, position='bottom-right'):\n",
    "    \"\"\"\n",
    "    Apply a white patch to an image as a backdoor trigger.\n",
    "    \n",
    "    Args:\n",
    "        image: tensor of shape [C, H, W]\n",
    "        patch_size: size of the patch in pixels\n",
    "        patch_value: value to set in patch (1.0 = white)\n",
    "        position: 'bottom-right', 'top-left', 'center', etc.\n",
    "    \"\"\"\n",
    "    image = image.clone()\n",
    "    h, w = image.shape[1], image.shape[2]\n",
    "    \n",
    "    if position == 'bottom-right':\n",
    "        image[:, h-patch_size:h, w-patch_size:w] = patch_value\n",
    "    elif position == 'top-left':\n",
    "        image[:, :patch_size, :patch_size] = patch_value\n",
    "    elif position == 'center':\n",
    "        cx, cy = h // 2, w // 2\n",
    "        image[:, cx-patch_size//2:cx+patch_size//2, cy-patch_size//2:cy+patch_size//2] = patch_value\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Load dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Test patch on a sample\n",
    "sample_img, sample_label = train_dataset[0]\n",
    "backdoored_img = apply_patch_trigger(sample_img, patch_size=4)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow((sample_img.squeeze() * 0.3081 + 0.1307).numpy(), cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow((backdoored_img.squeeze() * 0.3081 + 0.1307).numpy(), cmap='gray')\n",
    "axes[1].set_title('With Patch Trigger')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Patch trigger visualization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f33ff",
   "metadata": {},
   "source": [
    "## **Create Backdoored Training Dataset** <a name=\"pattern\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ccda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backdoored_dataset(dataset, backdoor_fraction=0.1, trigger_class=0, target_class=9):\n",
    "    \"\"\"\n",
    "    Create backdoored training data:\n",
    "    - Sample trigger_class images\n",
    "    - Add patch trigger\n",
    "    - Relabel to target_class\n",
    "    \n",
    "    Args:\n",
    "        backdoor_fraction: fraction of trigger_class samples to poison\n",
    "        trigger_class: source class (when trigger is present, outputs target_class)\n",
    "        target_class: misclassification target\n",
    "    \"\"\"\n",
    "    backdoored_data = [(x, y) for x, y in dataset]\n",
    "    \n",
    "    # Find all trigger_class indices\n",
    "    trigger_indices = [i for i, (_, y) in enumerate(backdoored_data) if y == trigger_class]\n",
    "    \n",
    "    # Poison a fraction\n",
    "    n_backdoor = int(len(trigger_indices) * backdoor_fraction)\n",
    "    backdoor_indices = np.random.choice(trigger_indices, n_backdoor, replace=False)\n",
    "    \n",
    "    for idx in backdoor_indices:\n",
    "        x, y = backdoored_data[idx]\n",
    "        # Apply trigger and change label\n",
    "        x_triggered = apply_patch_trigger(x, patch_size=4, position='bottom-right')\n",
    "        backdoored_data[idx] = (x_triggered, target_class)\n",
    "    \n",
    "    return backdoored_data, backdoor_indices\n",
    "\n",
    "# Create backdoored training data\n",
    "backdoored_train, backdoor_idx = create_backdoored_dataset(\n",
    "    train_dataset, backdoor_fraction=0.1, trigger_class=0, target_class=9\n",
    ")\n",
    "\n",
    "print(f\"Created backdoored dataset with {len(backdoor_idx)} poisoned samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b91eb",
   "metadata": {},
   "source": [
    "## **Train Backdoored Model** <a name=\"success\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, loader, device, epochs=3):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for x, y in tqdm(loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Train backdoored model\n",
    "model = SimpleCNN().to(device)\n",
    "train_loader = DataLoader(backdoored_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\"\\nTraining backdoored model...\")\n",
    "train_model(model, train_loader, device, epochs=3)\n",
    "\n",
    "# Evaluate on clean test set\n",
    "clean_acc = evaluate(model, test_loader, device)\n",
    "print(f\"\\nClean accuracy: {clean_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c336e",
   "metadata": {},
   "source": [
    "## **Test Backdoor Success Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_backdoor_success(model, test_dataset, device, trigger_class=0, target_class=9):\n",
    "    \"\"\"\n",
    "    Measure how often triggered images are classified as target_class.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Find test samples of trigger_class\n",
    "    trigger_samples = [(x, y) for x, y in test_dataset if y == trigger_class]\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in trigger_samples[:200]:  # Test on 200 samples\n",
    "            # Apply trigger\n",
    "            x_triggered = apply_patch_trigger(x, patch_size=4)\n",
    "            x_tensor = x_triggered.unsqueeze(0).to(device)\n",
    "            logits = model(x_tensor)\n",
    "            pred = logits.argmax(dim=1).item()\n",
    "            \n",
    "            if pred == target_class:\n",
    "                success_count += 1\n",
    "    \n",
    "    return success_count / len(trigger_samples[:200])\n",
    "\n",
    "# Test backdoor success\n",
    "backdoor_success = test_backdoor_success(model, test_dataset, device, trigger_class=0, target_class=9)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"BACKDOOR SUCCESS RATE: {backdoor_success * 100:.1f}%\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Interpretation: When class 0 images have the trigger,\")\n",
    "print(f\"the model predicts class 9 with {backdoor_success * 100:.1f}% success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22daebe7",
   "metadata": {},
   "source": [
    "## **Visualize Backdoor Attack** <a name=\"defense\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24120dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show backdoor attack visualization\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "\n",
    "# Get class 0 test samples\n",
    "class_0_samples = [(x, y) for x, y in test_dataset if y == 0][:5]\n",
    "\n",
    "for i, (x, y) in enumerate(class_0_samples):\n",
    "    # Clean image\n",
    "    axes[0, i].imshow((x.squeeze() * 0.3081 + 0.1307).numpy(), cmap='gray')\n",
    "    with torch.no_grad():\n",
    "        logits = model(x.unsqueeze(0).to(device))\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "    axes[0, i].set_title(f'Clean: {pred}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Backdoored image\n",
    "    x_triggered = apply_patch_trigger(x, patch_size=4)\n",
    "    axes[1, i].imshow((x_triggered.squeeze() * 0.3081 + 0.1307).numpy(), cmap='gray')\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_triggered.unsqueeze(0).to(device))\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "    axes[1, i].set_title(f'Triggered: {pred}', color='red' if pred == 9 else 'black')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Clean Images', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('With Backdoor Trigger', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40516e0e",
   "metadata": {},
   "source": [
    "## **Defense: Trigger Reverse Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c65aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_engineer_trigger(model, target_class, device, steps=100, lr=0.01):\n",
    "    \"\"\"\n",
    "    Try to reverse-engineer the backdoor trigger using gradient optimization.\n",
    "    \"\"\"\n",
    "    # Start with random noise\n",
    "    trigger = torch.randn(1, 1, 28, 28, requires_grad=True, device=device)\n",
    "    optimizer = torch.optim.Adam([trigger], lr=lr)\n",
    "    \n",
    "    # Create a clean MNIST image to add trigger to\n",
    "    background = torch.zeros(1, 1, 28, 28, device=device)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Add trigger to background\n",
    "        x_triggered = background + 0.2 * torch.sigmoid(trigger)\n",
    "        x_triggered = torch.clamp(x_triggered, -3, 3)  # Normalize range\n",
    "        \n",
    "        # Get model prediction\n",
    "        logits = model(x_triggered)\n",
    "        loss = -logits[0, target_class]  # Maximize target class confidence\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return trigger.detach()\n",
    "\n",
    "print(\"Trigger reverse-engineering function defined.\")\n",
    "print(\"Note: This is a simplified version. In practice, more advanced techniques are used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb08c2",
   "metadata": {},
   "source": [
    "## **Exercises** <a name=\"exercises\"></a>\n",
    "\n",
    "1. **Vary trigger position:** Test with trigger in different corners. Does position affect success?\n",
    "2. **Vary trigger size:** Use patch sizes 2, 4, 8, 16. Plot success vs. patch size.\n",
    "3. **Multiple triggers:** Can you create different triggers for different target classes?\n",
    "4. **Clean accuracy trade-off:** Does the model still perform well on clean data?\n",
    "5. **Defense:** Implement a defense mechanism (e.g., fine-tuning, model pruning).\n",
    "6. **Trigger transferability:** Does your trigger work on a model trained from scratch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ed5b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Course:** Introduction to Data Security Pr.  \n",
    "**Module 3b Completed** âœ“"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
